{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "torch",
      "language": "python",
      "name": "torch"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "trainings_loops.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1c59f8a"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# from data_loading import sine_data_generation\n",
        "# from utils import random_generator\n",
        "# from data_loading import MinMaxScaler\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "# from utils import extract_time\n"
      ],
      "id": "a1c59f8a",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahJcCrzPQl-k"
      },
      "source": [
        "def train_test_divide (data_x, data_x_hat, data_t, data_t_hat, train_rate = 0.8):\n",
        "  \"\"\"Divide train and test data for both original and synthetic data.\n",
        "  \n",
        "  Args:\n",
        "    - data_x: original data\n",
        "    - data_x_hat: generated data\n",
        "    - data_t: original time\n",
        "    - data_t_hat: generated time\n",
        "    - train_rate: ratio of training data from the original data\n",
        "  \"\"\"\n",
        "  # Divide train/test index (original data)\n",
        "  no = len(data_x)\n",
        "  idx = np.random.permutation(no)\n",
        "  train_idx = idx[:int(no*train_rate)]\n",
        "  test_idx = idx[int(no*train_rate):]\n",
        "    \n",
        "  train_x = [data_x[i] for i in train_idx]\n",
        "  test_x = [data_x[i] for i in test_idx]\n",
        "  train_t = [data_t[i] for i in train_idx]\n",
        "  test_t = [data_t[i] for i in test_idx]      \n",
        "    \n",
        "  # Divide train/test index (synthetic data)\n",
        "  no = len(data_x_hat)\n",
        "  idx = np.random.permutation(no)\n",
        "  train_idx = idx[:int(no*train_rate)]\n",
        "  test_idx = idx[int(no*train_rate):]\n",
        "  \n",
        "  train_x_hat = [data_x_hat[i] for i in train_idx]\n",
        "  test_x_hat = [data_x_hat[i] for i in test_idx]\n",
        "  train_t_hat = [data_t_hat[i] for i in train_idx]\n",
        "  test_t_hat = [data_t_hat[i] for i in test_idx]\n",
        "  \n",
        "  return train_x, train_x_hat, test_x, test_x_hat, train_t, train_t_hat, test_t, test_t_hat\n",
        "\n",
        "\n",
        "def extract_time (data):\n",
        "  \"\"\"Returns Maximum sequence length and each sequence length.\n",
        "  \n",
        "  Args:\n",
        "    - data: original data\n",
        "    \n",
        "  Returns:\n",
        "    - time: extracted time information\n",
        "    - max_seq_len: maximum sequence length\n",
        "  \"\"\"\n",
        "  time = list()\n",
        "  max_seq_len = 0\n",
        "  for i in range(len(data)):\n",
        "    max_seq_len = max(max_seq_len, len(data[i][:,0]))\n",
        "    time.append(len(data[i][:,0]))\n",
        "    \n",
        "  return time, max_seq_len\n",
        "\n",
        "def random_generator (batch_size, z_dim, T_mb, max_seq_len):\n",
        "  \"\"\"Random vector generation.\n",
        "  \n",
        "  Args:\n",
        "    - batch_size: size of the random vector\n",
        "    - z_dim: dimension of random vector\n",
        "    - T_mb: time information for the random vector\n",
        "    - max_seq_len: maximum sequence length\n",
        "    \n",
        "  Returns:\n",
        "    - Z_mb: generated random vector\n",
        "  \"\"\"\n",
        "  Z_mb = list()\n",
        "  for i in range(batch_size):\n",
        "    temp = np.zeros([max_seq_len, z_dim])\n",
        "    temp_Z = np.random.uniform(0., 1, [T_mb[i], z_dim])\n",
        "    temp[:T_mb[i],:] = temp_Z\n",
        "    Z_mb.append(temp_Z)\n",
        "  return Z_mb\n",
        "\n",
        "\n",
        "def batch_generator(data, time, batch_size):\n",
        "  \"\"\"Mini-batch generator.\n",
        "  \n",
        "  Args:\n",
        "    - data: time-series data\n",
        "    - time: time information\n",
        "    - batch_size: the number of samples in each batch\n",
        "    \n",
        "  Returns:\n",
        "    - X_mb: time-series data in each batch\n",
        "    - T_mb: time information in each batch\n",
        "  \"\"\"\n",
        "  no = len(data)\n",
        "  idx = np.random.permutation(no)\n",
        "  train_idx = idx[:batch_size]     \n",
        "            \n",
        "  X_mb = list(data[i] for i in train_idx)\n",
        "  T_mb = list(time[i] for i in train_idx)\n",
        "  \n",
        "  return X_mb, T_mb"
      ],
      "id": "ahJcCrzPQl-k",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsYQ9_Y1Qe70"
      },
      "source": [
        "def MinMaxScaler(data):\n",
        "  \"\"\"Min Max normalizer.\n",
        "  \n",
        "  Args:\n",
        "    - data: original data\n",
        "  \n",
        "  Returns:\n",
        "    - norm_data: normalized data\n",
        "  \"\"\"\n",
        "  numerator = data - np.min(data, 0)\n",
        "  denominator = np.max(data, 0) - np.min(data, 0)\n",
        "  norm_data = numerator / (denominator + 1e-7)\n",
        "  return norm_data\n",
        "\n",
        "\n",
        "def sine_data_generation (no, seq_len, dim):\n",
        "  \"\"\"Sine data generation.\n",
        "  \n",
        "  Args:\n",
        "    - no: the number of samples\n",
        "    - seq_len: sequence length of the time-series\n",
        "    - dim: feature dimensions\n",
        "    \n",
        "  Returns:\n",
        "    - data: generated data\n",
        "  \"\"\"  \n",
        "  # Initialize the output\n",
        "  data = list()\n",
        "\n",
        "  # Generate sine data\n",
        "  for i in range(no):      \n",
        "    # Initialize each time-series\n",
        "    temp = list()\n",
        "    # For each feature\n",
        "    for k in range(dim):\n",
        "      # Randomly drawn frequency and phase\n",
        "      freq = np.random.uniform(0, 0.1)            \n",
        "      phase = np.random.uniform(0, 0.1)\n",
        "          \n",
        "      # Generate sine signal based on the drawn frequency and phase\n",
        "      temp_data = [np.sin(freq * j + phase) for j in range(seq_len)] \n",
        "      temp.append(temp_data)\n",
        "        \n",
        "    # Align row/column\n",
        "    temp = np.transpose(np.asarray(temp))        \n",
        "    # Normalize to [0,1]\n",
        "    temp = (temp + 1)*0.5\n",
        "    # Stack the generated data\n",
        "    data.append(temp)\n",
        "                \n",
        "  return data\n",
        "    \n",
        "\n",
        "def real_data_loading (data_name, seq_len):\n",
        "  \"\"\"Load and preprocess real-world datasets.\n",
        "  \n",
        "  Args:\n",
        "    - data_name: stock or energy\n",
        "    - seq_len: sequence length\n",
        "    \n",
        "  Returns:\n",
        "    - data: preprocessed data.\n",
        "  \"\"\"  \n",
        "  assert data_name in ['stock','energy']\n",
        "  \n",
        "  if data_name == 'stock':\n",
        "    ori_data = np.loadtxt('data/stock_data.csv', delimiter = \",\",skiprows = 1)\n",
        "  elif data_name == 'energy':\n",
        "    ori_data = np.loadtxt('data/energy_data.csv', delimiter = \",\",skiprows = 1)\n",
        "        \n",
        "  # Flip the data to make chronological data\n",
        "  ori_data = ori_data[::-1]\n",
        "  # Normalize the data\n",
        "  ori_data = MinMaxScaler(ori_data)\n",
        "    \n",
        "  # Preprocess the dataset\n",
        "  temp_data = []    \n",
        "  # Cut data by sequence length\n",
        "  for i in range(0, len(ori_data) - seq_len):\n",
        "    _x = ori_data[i:i + seq_len]\n",
        "    temp_data.append(_x)\n",
        "        \n",
        "  # Mix the datasets (to make it similar to i.i.d)\n",
        "  idx = np.random.permutation(len(temp_data))    \n",
        "  data = []\n",
        "  for i in range(len(temp_data)):\n",
        "    data.append(temp_data[idx[i]])\n",
        "    \n",
        "  return data"
      ],
      "id": "KsYQ9_Y1Qe70",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e849290"
      },
      "source": [
        "Define Class for Module Construction"
      ],
      "id": "4e849290"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "294d9abe"
      },
      "source": [
        "class Time_GAN_module(nn.Module):\n",
        "    \"\"\"\n",
        "    Class from which a module of the Time GAN Architecture can be constructed, \n",
        "    consisting of a n_layer stacked RNN layers and a fully connected layer\n",
        "    \n",
        "    input_size = dim of data (depending if module operates on latent or non-latent space)\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, output_size, hidden_dim, n_layers, activation=torch.sigmoid):\n",
        "        super(Time_GAN_module, self).__init__()\n",
        "\n",
        "        # Parameters\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.sigma = activation\n",
        "\n",
        "        #Defining the layers\n",
        "        # RNN Layer\n",
        "        self.rnn = nn.GRU(input_size, hidden_dim, n_layers, batch_first=True)   \n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "        \n",
        "    def forward(self, x):\n",
        "    \n",
        "            batch_size = x.size(0)\n",
        "\n",
        "            # Initializing hidden state for first input using method defined below\n",
        "            hidden = self.init_hidden(batch_size)\n",
        "\n",
        "            # Passing in the input and hidden state into the model and obtaining outputs\n",
        "            out, hidden = self.rnn(x, hidden)\n",
        "        \n",
        "            # Reshaping the outputs such that it can be fit into the fully connected layer\n",
        "            out = out.contiguous().view(-1, self.hidden_dim)\n",
        "            out = self.fc(out)\n",
        "            \n",
        "            if self.sigma == nn.Identity:\n",
        "                idendity = nn.Identity()\n",
        "                return idendity(out)\n",
        "                \n",
        "            out = self.sigma(out)\n",
        "            \n",
        "            # HIDDEN STATES WERDEN IN DER PAPER IMPLEMENTIERUNG AUCH COMPUTED, ALLERDINGS NICHT BENUTZT?\n",
        "            \n",
        "            return out, hidden\n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
        "        # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
        "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim)\n",
        "        return hidden"
      ],
      "id": "294d9abe",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65ad1d5e"
      },
      "source": [
        "Parameters"
      ],
      "id": "65ad1d5e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a2e3f85"
      },
      "source": [
        "input_size = 5 # sequence length = number of features\n",
        "output_size = 20\n",
        "hidden_dim = 20\n",
        "n_layers = 3\n",
        "gamma = 1\n",
        "\n",
        "no, seq_len, dim = 12800, 24, 5 \n",
        "\n",
        "batch_size = 128\n",
        "epoch = 100"
      ],
      "id": "6a2e3f85",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b35b74eb"
      },
      "source": [
        "Data Generation"
      ],
      "id": "b35b74eb"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2373fb48",
        "outputId": "4dee01c1-2a49-48cd-ad89-6195e75e2705"
      },
      "source": [
        "data = sine_data_generation(no, seq_len, dim)\n",
        "data = MinMaxScaler(data)\n",
        "data = torch.Tensor(data)\n",
        "data.shape"
      ],
      "id": "2373fb48",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([12800, 24, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90e9892c"
      },
      "source": [
        "Create Modules"
      ],
      "id": "90e9892c"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVra-i_jieoc"
      },
      "source": [
        "# embedder: num_layers = num_layers, fully_connected dim = hidden_dim\n",
        "# recovery: num_layers = num_layers, fully_connected dim = dim \n",
        "# generator: num layers = num_layers, fully_connected dim = hidden_dim\n",
        "# supervisor: num_layers = num_layers-1, fully_connected dim = hidden_dim\n",
        "# discriminator: num_layers = num_layers, fully_connected dim = 1"
      ],
      "id": "nVra-i_jieoc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NU73wgsajAtM",
        "outputId": "7822f007-f72b-403e-a62c-3ca0343ca733"
      },
      "source": [
        ""
      ],
      "id": "NU73wgsajAtM",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db4e7203",
        "outputId": "b91c414e-94cd-40a5-8b29-85cddd2a4fe6"
      },
      "source": [
        "Embedder = Time_GAN_module(input_size=dim, output_size=hidden_dim, hidden_dim=hidden_dim, n_layers=n_layers)\n",
        "Embedder"
      ],
      "id": "db4e7203",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Time_GAN_module(\n",
              "  (rnn): GRU(5, 20, num_layers=3, batch_first=True)\n",
              "  (fc): Linear(in_features=20, out_features=20, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9edcdcda",
        "outputId": "165a8b40-6af6-4fb9-d9da-84184e4e612a"
      },
      "source": [
        "Recovery = Time_GAN_module(input_size=hidden_dim, output_size=dim, hidden_dim=hidden_dim, n_layers=n_layers)\n",
        "Recovery"
      ],
      "id": "9edcdcda",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Time_GAN_module(\n",
              "  (rnn): GRU(20, 20, num_layers=3, batch_first=True)\n",
              "  (fc): Linear(in_features=20, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "700d9516",
        "outputId": "64a907cd-a35a-448d-830a-1642e06ff34f"
      },
      "source": [
        "Generator = Time_GAN_module(input_size=dim, output_size=hidden_dim, hidden_dim=hidden_dim, n_layers=n_layers)\n",
        "Generator"
      ],
      "id": "700d9516",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Time_GAN_module(\n",
              "  (rnn): GRU(5, 20, num_layers=3, batch_first=True)\n",
              "  (fc): Linear(in_features=20, out_features=20, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "771283fc",
        "outputId": "a8ae0624-3074-4241-c9ac-6ff2266506db"
      },
      "source": [
        "Supervisor = Time_GAN_module(input_size=hidden_dim, output_size=hidden_dim, hidden_dim=hidden_dim, n_layers=n_layers-1)\n",
        "Supervisor"
      ],
      "id": "771283fc",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Time_GAN_module(\n",
              "  (rnn): GRU(20, 20, num_layers=2, batch_first=True)\n",
              "  (fc): Linear(in_features=20, out_features=20, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03e296b8",
        "outputId": "f9b560a8-7fcd-4700-9852-705d736070dc"
      },
      "source": [
        "Discriminator = Time_GAN_module(input_size=hidden_dim, output_size=1, hidden_dim=hidden_dim, n_layers=n_layers, \n",
        "                               activation=nn.Identity)\n",
        "Discriminator"
      ],
      "id": "03e296b8",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Time_GAN_module(\n",
              "  (rnn): GRU(20, 20, num_layers=3, batch_first=True)\n",
              "  (fc): Linear(in_features=20, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a27f997b"
      },
      "source": [
        "Create Optimizers"
      ],
      "id": "a27f997b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7aed175"
      },
      "source": [
        "embedder_optimizer = optim.Adam(Embedder.parameters(), lr=0.001)\n",
        "recovery_optimizer = optim.Adam(Recovery.parameters(), lr=0.001)\n",
        "supervisor_optimizer = optim.Adam(Recovery.parameters(), lr=0.001)\n",
        "discriminator_optimizer = optim.Adam(Discriminator.parameters(), lr=0.001)\n",
        "generator_optimizer = optim.Adam(Generator.parameters(), lr=0.001)"
      ],
      "id": "c7aed175",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a05ad143"
      },
      "source": [
        "Data Loader"
      ],
      "id": "a05ad143"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f04458be",
        "outputId": "574902d5-4a8e-4991-e66a-097d0f41eaf7"
      },
      "source": [
        "loader = DataLoader(data, batch_size, shuffle=True)\n",
        "X = next(iter(loader))\n",
        "H, _ = Embedder(X.float())\n",
        "H_re = torch.reshape(H, (batch_size, seq_len, hidden_dim))\n",
        "H.shape, H_re.shape"
      ],
      "id": "f04458be",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3072, 20]), torch.Size([128, 24, 20]))"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVFi9yxqeDqL",
        "outputId": "dca7ac02-d035-40f1-c152-9675fb0e1490"
      },
      "source": [
        "batch_size, seq_len, hidden_dim"
      ],
      "id": "xVFi9yxqeDqL",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128, 24, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcfd5039"
      },
      "source": [
        "Embedder Training"
      ],
      "id": "bcfd5039"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd9274ab",
        "outputId": "40a40d29-baaa-48f1-a47d-02e43321d1a6"
      },
      "source": [
        "print('Start Embedding Network Training')\n",
        "\n",
        "for e in range(epoch): \n",
        "    for batch_index, X in enumerate(loader):\n",
        "        \n",
        "        MSE_loss = nn.MSELoss()\n",
        "        \n",
        "        H, _ = Embedder(X.float())\n",
        "        H = torch.reshape(H, (batch_size, seq_len, hidden_dim))\n",
        "\n",
        "        X_tilde, _ = Recovery(H)\n",
        "        X_tilde = torch.reshape(X_tilde, (batch_size, seq_len, dim))\n",
        "\n",
        "        E_loss0 = 10 * torch.sqrt(MSE_loss(X, X_tilde))  \n",
        "\n",
        "        Embedder.zero_grad()\n",
        "        Recovery.zero_grad()\n",
        "\n",
        "        E_loss0.backward(retain_graph=True)\n",
        "\n",
        "        embedder_optimizer.step()\n",
        "        recovery_optimizer.step()\n",
        "\n",
        "        if e in range(1,epoch) and batch_index == 0:\n",
        "            print('step: '+ str(e) + '/' + str(epoch) + ', e_loss: ' + str(np.sqrt(E_loss0.detach().numpy())))\n",
        "\n",
        "print('Finish Embedding Network Training')"
      ],
      "id": "bd9274ab",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start Embedding Network Training\n",
            "step: 1/100, e_loss: 1.6242844\n",
            "step: 2/100, e_loss: 1.5305429\n",
            "step: 3/100, e_loss: 1.3659562\n",
            "step: 4/100, e_loss: 1.3657204\n",
            "step: 5/100, e_loss: 1.2694849\n",
            "step: 6/100, e_loss: 1.2935171\n",
            "step: 7/100, e_loss: 1.222938\n",
            "step: 8/100, e_loss: 1.2784274\n",
            "step: 9/100, e_loss: 1.2142535\n",
            "step: 10/100, e_loss: 1.1620075\n",
            "step: 11/100, e_loss: 1.0758421\n",
            "step: 12/100, e_loss: 1.0577039\n",
            "step: 13/100, e_loss: 1.1445479\n",
            "step: 14/100, e_loss: 0.7743927\n",
            "step: 15/100, e_loss: 0.66275954\n",
            "step: 16/100, e_loss: 0.59957975\n",
            "step: 17/100, e_loss: 0.5614518\n",
            "step: 18/100, e_loss: 0.5217093\n",
            "step: 19/100, e_loss: 0.5111664\n",
            "step: 20/100, e_loss: 0.5036501\n",
            "step: 21/100, e_loss: 0.48710972\n",
            "step: 22/100, e_loss: 0.48306465\n",
            "step: 23/100, e_loss: 0.46678847\n",
            "step: 24/100, e_loss: 0.45473978\n",
            "step: 25/100, e_loss: 0.44513795\n",
            "step: 26/100, e_loss: 0.44499373\n",
            "step: 27/100, e_loss: 0.4380458\n",
            "step: 28/100, e_loss: 0.43888602\n",
            "step: 29/100, e_loss: 0.41872013\n",
            "step: 30/100, e_loss: 0.4085132\n",
            "step: 31/100, e_loss: 0.41245633\n",
            "step: 32/100, e_loss: 0.3992154\n",
            "step: 33/100, e_loss: 0.39428177\n",
            "step: 34/100, e_loss: 0.38892823\n",
            "step: 35/100, e_loss: 0.3845043\n",
            "step: 36/100, e_loss: 0.3845259\n",
            "step: 37/100, e_loss: 0.37828094\n",
            "step: 38/100, e_loss: 0.38592657\n",
            "step: 39/100, e_loss: 0.37139496\n",
            "step: 40/100, e_loss: 0.37108013\n",
            "step: 41/100, e_loss: 0.38829243\n",
            "step: 42/100, e_loss: 0.3588918\n",
            "step: 43/100, e_loss: 0.37007397\n",
            "step: 44/100, e_loss: 0.36884663\n",
            "step: 45/100, e_loss: 0.3554155\n",
            "step: 46/100, e_loss: 0.35931116\n",
            "step: 47/100, e_loss: 0.3520748\n",
            "step: 48/100, e_loss: 0.34829894\n",
            "step: 49/100, e_loss: 0.3571032\n",
            "step: 50/100, e_loss: 0.34500766\n",
            "step: 51/100, e_loss: 0.34269285\n",
            "step: 52/100, e_loss: 0.34780475\n",
            "step: 53/100, e_loss: 0.3429168\n",
            "step: 54/100, e_loss: 0.34247512\n",
            "step: 55/100, e_loss: 0.34400207\n",
            "step: 56/100, e_loss: 0.3421753\n",
            "step: 57/100, e_loss: 0.3383911\n",
            "step: 58/100, e_loss: 0.33579603\n",
            "step: 59/100, e_loss: 0.34181413\n",
            "step: 60/100, e_loss: 0.33570933\n",
            "step: 61/100, e_loss: 0.32285756\n",
            "step: 62/100, e_loss: 0.33182633\n",
            "step: 63/100, e_loss: 0.3291346\n",
            "step: 64/100, e_loss: 0.3210019\n",
            "step: 65/100, e_loss: 0.3248935\n",
            "step: 66/100, e_loss: 0.31925192\n",
            "step: 67/100, e_loss: 0.32934055\n",
            "step: 68/100, e_loss: 0.32055983\n",
            "step: 69/100, e_loss: 0.3295068\n",
            "step: 70/100, e_loss: 0.33013242\n",
            "step: 71/100, e_loss: 0.3259598\n",
            "step: 72/100, e_loss: 0.32768825\n",
            "step: 73/100, e_loss: 0.32539603\n",
            "step: 74/100, e_loss: 0.32255793\n",
            "step: 75/100, e_loss: 0.3062609\n",
            "step: 76/100, e_loss: 0.31537995\n",
            "step: 77/100, e_loss: 0.32535273\n",
            "step: 78/100, e_loss: 0.31889454\n",
            "step: 79/100, e_loss: 0.31630176\n",
            "step: 80/100, e_loss: 0.31507915\n",
            "step: 81/100, e_loss: 0.313423\n",
            "step: 82/100, e_loss: 0.31655252\n",
            "step: 83/100, e_loss: 0.31732246\n",
            "step: 84/100, e_loss: 0.31102595\n",
            "step: 85/100, e_loss: 0.31075108\n",
            "step: 86/100, e_loss: 0.303361\n",
            "step: 87/100, e_loss: 0.30164576\n",
            "step: 88/100, e_loss: 0.29883686\n",
            "step: 89/100, e_loss: 0.30535555\n",
            "step: 90/100, e_loss: 0.3210539\n",
            "step: 91/100, e_loss: 0.29910827\n",
            "step: 92/100, e_loss: 0.30474076\n",
            "step: 93/100, e_loss: 0.3020227\n",
            "step: 94/100, e_loss: 0.3034886\n",
            "step: 95/100, e_loss: 0.3068544\n",
            "step: 96/100, e_loss: 0.30856118\n",
            "step: 97/100, e_loss: 0.29244983\n",
            "step: 98/100, e_loss: 0.29763663\n",
            "step: 99/100, e_loss: 0.30917653\n",
            "Finish Embedding Network Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1634b07"
      },
      "source": [
        "Training with supervised Loss"
      ],
      "id": "f1634b07"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c75a988f",
        "outputId": "8812cdfa-6446-4be9-e499-591a1bbec838"
      },
      "source": [
        "print('Start Training with Supervised Loss Only')\n",
        "\n",
        "for e in range(epoch): \n",
        "    for batch_index, X in enumerate(loader):\n",
        "\n",
        "        H, _ = Embedder(X.float())\n",
        "        H = torch.reshape(H, (batch_size, seq_len, hidden_dim))\n",
        "\n",
        "        H_hat_supervise, _ = Supervisor(H)\n",
        "        H_hat_supervise = torch.reshape(H_hat_supervise, (batch_size, seq_len, hidden_dim))  \n",
        "\n",
        "        G_loss_S = MSE_loss(H[:,1:,:], H_hat_supervise[:,:-1,:])\n",
        "\n",
        "\n",
        "        Embedder.zero_grad()\n",
        "        Supervisor.zero_grad()\n",
        "\n",
        "        G_loss_S.backward(retain_graph=True)\n",
        "\n",
        "        embedder_optimizer.step()\n",
        "        supervisor_optimizer.step()\n",
        "\n",
        "        if e in range(1,epoch) and batch_index == 0:\n",
        "            print('step: '+ str(e) + '/' + str(epoch) + ', s_loss: ' + str(np.sqrt(G_loss_S.detach().numpy())))\n",
        "\n",
        "print('Finish Training with Supervised Loss Only')"
      ],
      "id": "c75a988f",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start Training with Supervised Loss Only\n",
            "step: 1/100, s_loss: 0.09964683\n",
            "step: 2/100, s_loss: 0.09478158\n",
            "step: 3/100, s_loss: 0.092493\n",
            "step: 4/100, s_loss: 0.08582403\n",
            "step: 5/100, s_loss: 0.083220385\n",
            "step: 6/100, s_loss: 0.07979374\n",
            "step: 7/100, s_loss: 0.074106425\n",
            "step: 8/100, s_loss: 0.07030248\n",
            "step: 9/100, s_loss: 0.072493605\n",
            "step: 10/100, s_loss: 0.06692988\n",
            "step: 11/100, s_loss: 0.06455012\n",
            "step: 12/100, s_loss: 0.06289997\n",
            "step: 13/100, s_loss: 0.059171397\n",
            "step: 14/100, s_loss: 0.0561611\n",
            "step: 15/100, s_loss: 0.053076327\n",
            "step: 16/100, s_loss: 0.05145452\n",
            "step: 17/100, s_loss: 0.047989562\n",
            "step: 18/100, s_loss: 0.044613775\n",
            "step: 19/100, s_loss: 0.042740956\n",
            "step: 20/100, s_loss: 0.03997947\n",
            "step: 21/100, s_loss: 0.038406666\n",
            "step: 22/100, s_loss: 0.038452793\n",
            "step: 23/100, s_loss: 0.035605773\n",
            "step: 24/100, s_loss: 0.03442791\n",
            "step: 25/100, s_loss: 0.032908514\n",
            "step: 26/100, s_loss: 0.03171904\n",
            "step: 27/100, s_loss: 0.029951302\n",
            "step: 28/100, s_loss: 0.028834099\n",
            "step: 29/100, s_loss: 0.028288601\n",
            "step: 30/100, s_loss: 0.026867647\n",
            "step: 31/100, s_loss: 0.024702491\n",
            "step: 32/100, s_loss: 0.02528292\n",
            "step: 33/100, s_loss: 0.023304423\n",
            "step: 34/100, s_loss: 0.022734763\n",
            "step: 35/100, s_loss: 0.022860697\n",
            "step: 36/100, s_loss: 0.021795161\n",
            "step: 37/100, s_loss: 0.020720478\n",
            "step: 38/100, s_loss: 0.02108492\n",
            "step: 39/100, s_loss: 0.0195224\n",
            "step: 40/100, s_loss: 0.018501285\n",
            "step: 41/100, s_loss: 0.01850534\n",
            "step: 42/100, s_loss: 0.01730817\n",
            "step: 43/100, s_loss: 0.017487042\n",
            "step: 44/100, s_loss: 0.016650064\n",
            "step: 45/100, s_loss: 0.01586118\n",
            "step: 46/100, s_loss: 0.015419619\n",
            "step: 47/100, s_loss: 0.01509535\n",
            "step: 48/100, s_loss: 0.014559614\n",
            "step: 49/100, s_loss: 0.014284575\n",
            "step: 50/100, s_loss: 0.013610347\n",
            "step: 51/100, s_loss: 0.013406681\n",
            "step: 52/100, s_loss: 0.013053508\n",
            "step: 53/100, s_loss: 0.0126679875\n",
            "step: 54/100, s_loss: 0.012118604\n",
            "step: 55/100, s_loss: 0.011981901\n",
            "step: 56/100, s_loss: 0.011179211\n",
            "step: 57/100, s_loss: 0.011012429\n",
            "step: 58/100, s_loss: 0.010738596\n",
            "step: 59/100, s_loss: 0.010255175\n",
            "step: 60/100, s_loss: 0.00967701\n",
            "step: 61/100, s_loss: 0.009615674\n",
            "step: 62/100, s_loss: 0.009379623\n",
            "step: 63/100, s_loss: 0.009103575\n",
            "step: 64/100, s_loss: 0.008910764\n",
            "step: 65/100, s_loss: 0.008584712\n",
            "step: 66/100, s_loss: 0.008442634\n",
            "step: 67/100, s_loss: 0.007933528\n",
            "step: 68/100, s_loss: 0.007787604\n",
            "step: 69/100, s_loss: 0.0076222993\n",
            "step: 70/100, s_loss: 0.007446125\n",
            "step: 71/100, s_loss: 0.0069868346\n",
            "step: 72/100, s_loss: 0.0070617944\n",
            "step: 73/100, s_loss: 0.0068392023\n",
            "step: 74/100, s_loss: 0.006529394\n",
            "step: 75/100, s_loss: 0.006536999\n",
            "step: 76/100, s_loss: 0.0063466104\n",
            "step: 77/100, s_loss: 0.0062261326\n",
            "step: 78/100, s_loss: 0.0061889603\n",
            "step: 79/100, s_loss: 0.0059173787\n",
            "step: 80/100, s_loss: 0.0057402933\n",
            "step: 81/100, s_loss: 0.005795222\n",
            "step: 82/100, s_loss: 0.0055537564\n",
            "step: 83/100, s_loss: 0.0053505716\n",
            "step: 84/100, s_loss: 0.0050878227\n",
            "step: 85/100, s_loss: 0.0049465117\n",
            "step: 86/100, s_loss: 0.004773664\n",
            "step: 87/100, s_loss: 0.0046948455\n",
            "step: 88/100, s_loss: 0.0048179557\n",
            "step: 89/100, s_loss: 0.0045903055\n",
            "step: 90/100, s_loss: 0.004341908\n",
            "step: 91/100, s_loss: 0.00444895\n",
            "step: 92/100, s_loss: 0.0041767126\n",
            "step: 93/100, s_loss: 0.0041216942\n",
            "step: 94/100, s_loss: 0.003941076\n",
            "step: 95/100, s_loss: 0.0038688513\n",
            "step: 96/100, s_loss: 0.0037284908\n",
            "step: 97/100, s_loss: 0.003678462\n",
            "step: 98/100, s_loss: 0.0034989333\n",
            "step: 99/100, s_loss: 0.0034186372\n",
            "Finish Training with Supervised Loss Only\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1040c2c0"
      },
      "source": [
        "epoch = 2"
      ],
      "id": "1040c2c0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e2cd6ad"
      },
      "source": [
        "random_data = random_generator(batch_size=batch_size, z_dim=dim, \n",
        "                                       T_mb=extract_time(data)[0], max_seq_len=extract_time(data)[1])"
      ],
      "id": "9e2cd6ad",
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "627dd17f"
      },
      "source": [
        "loader = DataLoader(data, batch_size, shuffle=True)\n",
        "\n",
        "random_loader = DataLoader(random_data, batch_size, shuffle=True)\n",
        "\n",
        "binary_cross_entropy_loss = nn.BCEWithLogitsLoss()\n",
        "\n",
        "MSE_loss = nn.MSELoss()\n",
        "\n"
      ],
      "id": "627dd17f",
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3i8UwTo2kuXi",
        "outputId": "95ccad72-df37-4765-8ae1-c465dc907b46"
      },
      "source": [
        "X = next(iter(loader))\n",
        "X.shape"
      ],
      "id": "3i8UwTo2kuXi",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 24, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bede8319",
        "outputId": "5e3a1357-b74c-4c38-a82e-a604dc2afec8"
      },
      "source": [
        "print('Start Joint Training')\n",
        "\n",
        "for e in range(epoch): \n",
        "\n",
        "    for batch_index, X in enumerate(loader):\n",
        "        \n",
        "        random_data = random_generator(batch_size=batch_size, z_dim=dim, \n",
        "                                       T_mb=extract_time(data)[0], max_seq_len=extract_time(data)[1])\n",
        "        \n",
        "        \n",
        "        # Generator Training \n",
        "        ## Train Generator\n",
        "        z = torch.tensor(random_data)\n",
        "        z = z.float()\n",
        "        \n",
        "        e_hat, _ = Generator(z)\n",
        "        e_hat = torch.reshape(e_hat, (batch_size, seq_len, hidden_dim))\n",
        "        \n",
        "        H_hat, _ = Supervisor(e_hat)\n",
        "        H_hat = torch.reshape(H_hat, (batch_size, seq_len, hidden_dim))\n",
        "        \n",
        "        Y_fake = Discriminator(H_hat)\n",
        "        Y_fake = torch.reshape(Y_fake, (batch_size, seq_len, 1))\n",
        "        \n",
        "        x_hat, _ = Recovery(H_hat)\n",
        "        x_hat = torch.reshape(x_hat, (batch_size, seq_len, dim))\n",
        "        \n",
        "        \n",
        "        Generator.zero_grad()\n",
        "        Supervisor.zero_grad()\n",
        "        Discriminator.zero_grad()\n",
        "        Recovery.zero_grad()\n",
        "        \n",
        "        G_loss_U = binary_cross_entropy_loss(torch.ones_like(Y_fake), Y_fake)\n",
        "        \n",
        "        G_loss_V1 = torch.mean(torch.abs((torch.std(x_hat, [0], unbiased = False)) + 1e-6 - (torch.std(X, [0]) + 1e-6)))\n",
        "        G_loss_V2 = torch.mean(torch.abs((torch.mean(x_hat, [0]) - (torch.mean(X, [0])))))\n",
        "        G_loss_V = G_loss_V1 + G_loss_V2\n",
        "        \n",
        " \n",
        "        G_loss_U.backward(retain_graph=True)\n",
        "        G_loss_V.backward()\n",
        "\n",
        "\n",
        "        generator_optimizer.step()\n",
        "        supervisor_optimizer.step()\n",
        "        discriminator_optimizer.step()\n",
        "        \n",
        "        ## Train Embedder\n",
        "        \n",
        "        MSE_loss = nn.MSELoss()\n",
        "        \n",
        "        H, _ = Embedder(X.float())\n",
        "        H = torch.reshape(H, (batch_size, seq_len, hidden_dim))\n",
        "\n",
        "        X_tilde, _ = Recovery(H)\n",
        "        X_tilde = torch.reshape(X_tilde, (batch_size, seq_len, dim))\n",
        "\n",
        "        E_loss0 = 10 * torch.sqrt(MSE_loss(X, X_tilde))  \n",
        "        \n",
        "        H_hat_supervise, _ = Supervisor(H)\n",
        "        H_hat_supervise = torch.reshape(H_hat_supervise, (batch_size, seq_len, hidden_dim))  \n",
        "\n",
        "        G_loss_S = MSE_loss(H[:,1:,:], H_hat_supervise[:,:-1,:])\n",
        "        E_loss = E_loss0  + 0.1 * G_loss_S\n",
        "        \n",
        "        G_loss_S.backward(retain_graph=True)\n",
        "        E_loss.backward()\n",
        "        \n",
        "        Embedder.zero_grad()\n",
        "        Recovery.zero_grad()\n",
        "        Supervisor.zero_grad()\n",
        "        \n",
        "        embedder_optimizer.step()\n",
        "        recovery_optimizer.step()\n",
        "        supervisor_optimizer.step()\n",
        "        \n",
        "        # Train Discriminator \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        #if e in range(1,epoch) and batch_index == 0:\n",
        "        print('step: '+ str(e) + '/' + str(epoch) + ', G_loss_U: ' + str(G_loss_U.detach().numpy()) + ', G_loss_S: ' + \n",
        "             str(G_loss_S.detach().numpy()) + ', E_loss_t0: ' + str(np.sqrt(E_loss0.detach().numpy()))\n",
        "             )\n",
        "        \n",
        "        \n",
        " \n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "print('Finish Joint Training')"
      ],
      "id": "bede8319",
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start Joint Training\n",
            "step: 0/100, G_loss_U: 1.4394455, G_loss_S: 0.014505937, E_loss_t0: 0.9148896\n",
            "step: 0/100, G_loss_U: 1.4058028, G_loss_S: 0.014278081, E_loss_t0: 1.1607499\n",
            "step: 0/100, G_loss_U: 1.3720822, G_loss_S: 0.0150696, E_loss_t0: 1.3012395\n",
            "step: 0/100, G_loss_U: 1.337973, G_loss_S: 0.015141654, E_loss_t0: 1.3972374\n",
            "step: 0/100, G_loss_U: 1.303175, G_loss_S: 0.014511943, E_loss_t0: 1.4525503\n",
            "step: 0/100, G_loss_U: 1.2674292, G_loss_S: 0.014494549, E_loss_t0: 1.4723309\n",
            "step: 0/100, G_loss_U: 1.2305313, G_loss_S: 0.015746579, E_loss_t0: 1.4403359\n",
            "step: 0/100, G_loss_U: 1.1922926, G_loss_S: 0.01545319, E_loss_t0: 1.4194582\n",
            "step: 0/100, G_loss_U: 1.1525235, G_loss_S: 0.015509402, E_loss_t0: 1.3867619\n",
            "step: 0/100, G_loss_U: 1.1110077, G_loss_S: 0.015286287, E_loss_t0: 1.3373346\n",
            "step: 0/100, G_loss_U: 1.067526, G_loss_S: 0.014792403, E_loss_t0: 1.3064687\n",
            "step: 0/100, G_loss_U: 1.0218762, G_loss_S: 0.015891239, E_loss_t0: 1.2551064\n",
            "step: 0/100, G_loss_U: 0.97388834, G_loss_S: 0.015252268, E_loss_t0: 1.2356023\n",
            "step: 0/100, G_loss_U: 0.9234367, G_loss_S: 0.015228049, E_loss_t0: 1.2238508\n",
            "step: 0/100, G_loss_U: 0.8704362, G_loss_S: 0.015210391, E_loss_t0: 1.2186784\n",
            "step: 0/100, G_loss_U: 0.814836, G_loss_S: 0.014909292, E_loss_t0: 1.213571\n",
            "step: 0/100, G_loss_U: 0.75664455, G_loss_S: 0.014401298, E_loss_t0: 1.2246293\n",
            "step: 0/100, G_loss_U: 0.69590473, G_loss_S: 0.014286144, E_loss_t0: 1.2249216\n",
            "step: 0/100, G_loss_U: 0.63271374, G_loss_S: 0.015955102, E_loss_t0: 1.2294664\n",
            "step: 0/100, G_loss_U: 0.567218, G_loss_S: 0.015577097, E_loss_t0: 1.249547\n",
            "step: 0/100, G_loss_U: 0.49962112, G_loss_S: 0.015341453, E_loss_t0: 1.2690548\n",
            "step: 0/100, G_loss_U: 0.43016574, G_loss_S: 0.0144582, E_loss_t0: 1.3018354\n",
            "step: 0/100, G_loss_U: 0.3591243, G_loss_S: 0.01462998, E_loss_t0: 1.3003787\n",
            "step: 0/100, G_loss_U: 0.28679952, G_loss_S: 0.015201417, E_loss_t0: 1.29352\n",
            "step: 0/100, G_loss_U: 0.2135086, G_loss_S: 0.015073132, E_loss_t0: 1.3082384\n",
            "step: 0/100, G_loss_U: 0.13957444, G_loss_S: 0.015090907, E_loss_t0: 1.3136503\n",
            "step: 0/100, G_loss_U: 0.06533293, G_loss_S: 0.01534113, E_loss_t0: 1.3217349\n",
            "step: 0/100, G_loss_U: -0.008882585, G_loss_S: 0.015025613, E_loss_t0: 1.3312111\n",
            "step: 0/100, G_loss_U: -0.08274474, G_loss_S: 0.015857527, E_loss_t0: 1.3219472\n",
            "step: 0/100, G_loss_U: -0.15594488, G_loss_S: 0.015475532, E_loss_t0: 1.3361509\n",
            "step: 0/100, G_loss_U: -0.22819094, G_loss_S: 0.015282146, E_loss_t0: 1.3376596\n",
            "step: 0/100, G_loss_U: -0.29922622, G_loss_S: 0.014770856, E_loss_t0: 1.339269\n",
            "step: 0/100, G_loss_U: -0.368832, G_loss_S: 0.015290712, E_loss_t0: 1.3151736\n",
            "step: 0/100, G_loss_U: -0.43683687, G_loss_S: 0.014685554, E_loss_t0: 1.3191373\n",
            "step: 0/100, G_loss_U: -0.50311846, G_loss_S: 0.015570806, E_loss_t0: 1.2922654\n",
            "step: 0/100, G_loss_U: -0.56759256, G_loss_S: 0.015595352, E_loss_t0: 1.2918996\n",
            "step: 0/100, G_loss_U: -0.6302114, G_loss_S: 0.01571433, E_loss_t0: 1.2894087\n",
            "step: 0/100, G_loss_U: -0.69096375, G_loss_S: 0.015031998, E_loss_t0: 1.3076098\n",
            "step: 0/100, G_loss_U: -0.7498649, G_loss_S: 0.014649163, E_loss_t0: 1.3275355\n",
            "step: 0/100, G_loss_U: -0.80695146, G_loss_S: 0.016216429, E_loss_t0: 1.3069583\n",
            "step: 0/100, G_loss_U: -0.8622754, G_loss_S: 0.015472777, E_loss_t0: 1.3292707\n",
            "step: 0/100, G_loss_U: -0.91589934, G_loss_S: 0.015533693, E_loss_t0: 1.3381159\n",
            "step: 0/100, G_loss_U: -0.96789175, G_loss_S: 0.015671441, E_loss_t0: 1.345745\n",
            "step: 0/100, G_loss_U: -1.0183295, G_loss_S: 0.015034369, E_loss_t0: 1.3401208\n",
            "step: 0/100, G_loss_U: -1.0672872, G_loss_S: 0.016216513, E_loss_t0: 1.3160733\n",
            "step: 0/100, G_loss_U: -1.1148423, G_loss_S: 0.015616554, E_loss_t0: 1.3136723\n",
            "step: 0/100, G_loss_U: -1.1610702, G_loss_S: 0.016302045, E_loss_t0: 1.326107\n",
            "step: 0/100, G_loss_U: -1.206045, G_loss_S: 0.014826194, E_loss_t0: 1.332848\n",
            "step: 0/100, G_loss_U: -1.2498374, G_loss_S: 0.015403057, E_loss_t0: 1.3149664\n",
            "step: 0/100, G_loss_U: -1.2925172, G_loss_S: 0.015100367, E_loss_t0: 1.3105682\n",
            "step: 0/100, G_loss_U: -1.3341519, G_loss_S: 0.015405362, E_loss_t0: 1.3035798\n",
            "step: 0/100, G_loss_U: -1.374806, G_loss_S: 0.015034264, E_loss_t0: 1.3001918\n",
            "step: 0/100, G_loss_U: -1.4145435, G_loss_S: 0.015214068, E_loss_t0: 1.3117061\n",
            "step: 0/100, G_loss_U: -1.4534224, G_loss_S: 0.014388408, E_loss_t0: 1.3106514\n",
            "step: 0/100, G_loss_U: -1.4914995, G_loss_S: 0.015667802, E_loss_t0: 1.2970985\n",
            "step: 0/100, G_loss_U: -1.5288323, G_loss_S: 0.0155997835, E_loss_t0: 1.2960297\n",
            "step: 0/100, G_loss_U: -1.565473, G_loss_S: 0.015409941, E_loss_t0: 1.3177767\n",
            "step: 0/100, G_loss_U: -1.601471, G_loss_S: 0.015209242, E_loss_t0: 1.3175429\n",
            "step: 0/100, G_loss_U: -1.6368737, G_loss_S: 0.015003917, E_loss_t0: 1.2902887\n",
            "step: 0/100, G_loss_U: -1.6717243, G_loss_S: 0.014942717, E_loss_t0: 1.311208\n",
            "step: 0/100, G_loss_U: -1.7060639, G_loss_S: 0.015429752, E_loss_t0: 1.3043778\n",
            "step: 0/100, G_loss_U: -1.7399293, G_loss_S: 0.014133925, E_loss_t0: 1.3413208\n",
            "step: 0/100, G_loss_U: -1.7733555, G_loss_S: 0.014932696, E_loss_t0: 1.2926437\n",
            "step: 0/100, G_loss_U: -1.8063726, G_loss_S: 0.015196317, E_loss_t0: 1.2826248\n",
            "step: 0/100, G_loss_U: -1.8390106, G_loss_S: 0.01553692, E_loss_t0: 1.2892461\n",
            "step: 0/100, G_loss_U: -1.8712969, G_loss_S: 0.015210839, E_loss_t0: 1.3107285\n",
            "step: 0/100, G_loss_U: -1.9032546, G_loss_S: 0.01559154, E_loss_t0: 1.35079\n",
            "step: 0/100, G_loss_U: -1.9349064, G_loss_S: 0.015272226, E_loss_t0: 1.3497916\n",
            "step: 0/100, G_loss_U: -1.9662724, G_loss_S: 0.014977703, E_loss_t0: 1.3406285\n",
            "step: 0/100, G_loss_U: -1.9973706, G_loss_S: 0.015930125, E_loss_t0: 1.2824831\n",
            "step: 0/100, G_loss_U: -2.0282166, G_loss_S: 0.015453468, E_loss_t0: 1.2927432\n",
            "step: 0/100, G_loss_U: -2.0588276, G_loss_S: 0.0147885615, E_loss_t0: 1.2762257\n",
            "step: 0/100, G_loss_U: -2.0892162, G_loss_S: 0.015868029, E_loss_t0: 1.2925099\n",
            "step: 0/100, G_loss_U: -2.1193953, G_loss_S: 0.015651092, E_loss_t0: 1.3322514\n",
            "step: 0/100, G_loss_U: -2.149376, G_loss_S: 0.0143646225, E_loss_t0: 1.347195\n",
            "step: 0/100, G_loss_U: -2.1791677, G_loss_S: 0.015885968, E_loss_t0: 1.3292257\n",
            "step: 0/100, G_loss_U: -2.2087815, G_loss_S: 0.015427928, E_loss_t0: 1.3000529\n",
            "step: 0/100, G_loss_U: -2.2382262, G_loss_S: 0.014965377, E_loss_t0: 1.290982\n",
            "step: 0/100, G_loss_U: -2.2675107, G_loss_S: 0.015758816, E_loss_t0: 1.2777529\n",
            "step: 0/100, G_loss_U: -2.296642, G_loss_S: 0.014620073, E_loss_t0: 1.3172735\n",
            "step: 0/100, G_loss_U: -2.325624, G_loss_S: 0.015216606, E_loss_t0: 1.3022808\n",
            "step: 0/100, G_loss_U: -2.3544662, G_loss_S: 0.016104087, E_loss_t0: 1.3169264\n",
            "step: 0/100, G_loss_U: -2.3831742, G_loss_S: 0.015919156, E_loss_t0: 1.3312223\n",
            "step: 0/100, G_loss_U: -2.4117544, G_loss_S: 0.015932493, E_loss_t0: 1.340554\n",
            "step: 0/100, G_loss_U: -2.4402099, G_loss_S: 0.016014758, E_loss_t0: 1.3657663\n",
            "step: 0/100, G_loss_U: -2.4685473, G_loss_S: 0.0155038005, E_loss_t0: 1.3630726\n",
            "step: 0/100, G_loss_U: -2.49677, G_loss_S: 0.01470788, E_loss_t0: 1.3393602\n",
            "step: 0/100, G_loss_U: -2.5248826, G_loss_S: 0.015481185, E_loss_t0: 1.3099613\n",
            "step: 0/100, G_loss_U: -2.5528886, G_loss_S: 0.0144479675, E_loss_t0: 1.2815021\n",
            "step: 0/100, G_loss_U: -2.5807917, G_loss_S: 0.016018827, E_loss_t0: 1.2844856\n",
            "step: 0/100, G_loss_U: -2.6085973, G_loss_S: 0.014932217, E_loss_t0: 1.3183974\n",
            "step: 0/100, G_loss_U: -2.6363077, G_loss_S: 0.015820418, E_loss_t0: 1.3339219\n",
            "step: 0/100, G_loss_U: -2.6639252, G_loss_S: 0.016466547, E_loss_t0: 1.3589877\n",
            "step: 0/100, G_loss_U: -2.6914551, G_loss_S: 0.01469898, E_loss_t0: 1.3807675\n",
            "step: 0/100, G_loss_U: -2.7188947, G_loss_S: 0.015550406, E_loss_t0: 1.3653674\n",
            "step: 0/100, G_loss_U: -2.7462494, G_loss_S: 0.015306177, E_loss_t0: 1.3318365\n",
            "step: 0/100, G_loss_U: -2.7735233, G_loss_S: 0.015434887, E_loss_t0: 1.3001732\n",
            "step: 0/100, G_loss_U: -2.8007195, G_loss_S: 0.016371591, E_loss_t0: 1.2859184\n",
            "step: 0/100, G_loss_U: -2.8278396, G_loss_S: 0.01550978, E_loss_t0: 1.3319767\n",
            "step: 0/100, G_loss_U: -2.8548825, G_loss_S: 0.014391086, E_loss_t0: 1.3471239\n",
            "step: 1/100, G_loss_U: -2.8818512, G_loss_S: 0.015256381, E_loss_t0: 1.3263271\n",
            "step: 1/100, G_loss_U: -2.9087493, G_loss_S: 0.01507736, E_loss_t0: 1.2885522\n",
            "step: 1/100, G_loss_U: -2.9355757, G_loss_S: 0.015107213, E_loss_t0: 1.2902992\n",
            "step: 1/100, G_loss_U: -2.9623382, G_loss_S: 0.015794858, E_loss_t0: 1.2965907\n",
            "step: 1/100, G_loss_U: -2.989035, G_loss_S: 0.015714547, E_loss_t0: 1.3257489\n",
            "step: 1/100, G_loss_U: -3.0156667, G_loss_S: 0.015186722, E_loss_t0: 1.3513789\n",
            "step: 1/100, G_loss_U: -3.0422356, G_loss_S: 0.015922982, E_loss_t0: 1.3423082\n",
            "step: 1/100, G_loss_U: -3.0687435, G_loss_S: 0.01497736, E_loss_t0: 1.313468\n",
            "step: 1/100, G_loss_U: -3.09519, G_loss_S: 0.015738191, E_loss_t0: 1.2974162\n",
            "step: 1/100, G_loss_U: -3.1215785, G_loss_S: 0.01476428, E_loss_t0: 1.2667315\n",
            "step: 1/100, G_loss_U: -3.147909, G_loss_S: 0.01556764, E_loss_t0: 1.257526\n",
            "step: 1/100, G_loss_U: -3.1741827, G_loss_S: 0.014600331, E_loss_t0: 1.3032168\n",
            "step: 1/100, G_loss_U: -3.2004035, G_loss_S: 0.01601349, E_loss_t0: 1.3735173\n",
            "step: 1/100, G_loss_U: -3.2265742, G_loss_S: 0.015473955, E_loss_t0: 1.399403\n",
            "step: 1/100, G_loss_U: -3.252692, G_loss_S: 0.015045358, E_loss_t0: 1.3915604\n",
            "step: 1/100, G_loss_U: -3.2787514, G_loss_S: 0.0152739985, E_loss_t0: 1.348714\n",
            "step: 1/100, G_loss_U: -3.30476, G_loss_S: 0.01567829, E_loss_t0: 1.3002001\n",
            "step: 1/100, G_loss_U: -3.330719, G_loss_S: 0.015562482, E_loss_t0: 1.2919983\n",
            "step: 1/100, G_loss_U: -3.3566306, G_loss_S: 0.015246569, E_loss_t0: 1.294014\n",
            "step: 1/100, G_loss_U: -3.3824952, G_loss_S: 0.015491776, E_loss_t0: 1.3423543\n",
            "step: 1/100, G_loss_U: -3.408312, G_loss_S: 0.015304968, E_loss_t0: 1.3640476\n",
            "step: 1/100, G_loss_U: -3.4340837, G_loss_S: 0.015032812, E_loss_t0: 1.3162524\n",
            "step: 1/100, G_loss_U: -3.4598017, G_loss_S: 0.015541991, E_loss_t0: 1.3078291\n",
            "step: 1/100, G_loss_U: -3.485479, G_loss_S: 0.016247531, E_loss_t0: 1.3234406\n",
            "step: 1/100, G_loss_U: -3.5111148, G_loss_S: 0.016212642, E_loss_t0: 1.3573775\n",
            "step: 1/100, G_loss_U: -3.536707, G_loss_S: 0.015592076, E_loss_t0: 1.4012808\n",
            "step: 1/100, G_loss_U: -3.5622547, G_loss_S: 0.014320046, E_loss_t0: 1.3968253\n",
            "step: 1/100, G_loss_U: -3.587756, G_loss_S: 0.015029562, E_loss_t0: 1.3259389\n",
            "step: 1/100, G_loss_U: -3.613217, G_loss_S: 0.0150092095, E_loss_t0: 1.2817452\n",
            "step: 1/100, G_loss_U: -3.6386375, G_loss_S: 0.014826195, E_loss_t0: 1.2466073\n",
            "step: 1/100, G_loss_U: -3.6640167, G_loss_S: 0.015030326, E_loss_t0: 1.24579\n",
            "step: 1/100, G_loss_U: -3.6893609, G_loss_S: 0.015719872, E_loss_t0: 1.2821698\n",
            "step: 1/100, G_loss_U: -3.7146626, G_loss_S: 0.015795657, E_loss_t0: 1.3167461\n",
            "step: 1/100, G_loss_U: -3.739929, G_loss_S: 0.0147015285, E_loss_t0: 1.3557173\n",
            "step: 1/100, G_loss_U: -3.7651482, G_loss_S: 0.015783988, E_loss_t0: 1.356981\n",
            "step: 1/100, G_loss_U: -3.7903311, G_loss_S: 0.015395057, E_loss_t0: 1.3475205\n",
            "step: 1/100, G_loss_U: -3.8154728, G_loss_S: 0.015666667, E_loss_t0: 1.3334559\n",
            "step: 1/100, G_loss_U: -3.840583, G_loss_S: 0.014769967, E_loss_t0: 1.389414\n",
            "step: 1/100, G_loss_U: -3.865661, G_loss_S: 0.015528471, E_loss_t0: 1.3514177\n",
            "step: 1/100, G_loss_U: -3.8906937, G_loss_S: 0.015330156, E_loss_t0: 1.3003511\n",
            "step: 1/100, G_loss_U: -3.9156902, G_loss_S: 0.015794745, E_loss_t0: 1.2642657\n",
            "step: 1/100, G_loss_U: -3.940651, G_loss_S: 0.015152338, E_loss_t0: 1.3212998\n",
            "step: 1/100, G_loss_U: -3.9655793, G_loss_S: 0.01527141, E_loss_t0: 1.3596736\n",
            "step: 1/100, G_loss_U: -3.9904776, G_loss_S: 0.015516563, E_loss_t0: 1.3329746\n",
            "step: 1/100, G_loss_U: -4.0153337, G_loss_S: 0.01531533, E_loss_t0: 1.3276932\n",
            "step: 1/100, G_loss_U: -4.0401554, G_loss_S: 0.015677063, E_loss_t0: 1.350471\n",
            "step: 1/100, G_loss_U: -4.064942, G_loss_S: 0.01506055, E_loss_t0: 1.3868389\n",
            "step: 1/100, G_loss_U: -4.0897007, G_loss_S: 0.015270862, E_loss_t0: 1.3976563\n",
            "step: 1/100, G_loss_U: -4.1144176, G_loss_S: 0.014729548, E_loss_t0: 1.3768343\n",
            "step: 1/100, G_loss_U: -4.1391063, G_loss_S: 0.015586868, E_loss_t0: 1.4130887\n",
            "step: 1/100, G_loss_U: -4.1637588, G_loss_S: 0.014946436, E_loss_t0: 1.4151592\n",
            "step: 1/100, G_loss_U: -4.1883845, G_loss_S: 0.01612343, E_loss_t0: 1.4420819\n",
            "step: 1/100, G_loss_U: -4.2129726, G_loss_S: 0.015903318, E_loss_t0: 1.4225976\n",
            "step: 1/100, G_loss_U: -4.23753, G_loss_S: 0.015136178, E_loss_t0: 1.4514277\n",
            "step: 1/100, G_loss_U: -4.262058, G_loss_S: 0.014680143, E_loss_t0: 1.4757595\n",
            "step: 1/100, G_loss_U: -4.2865586, G_loss_S: 0.014273451, E_loss_t0: 1.4945819\n",
            "step: 1/100, G_loss_U: -4.3110237, G_loss_S: 0.014820843, E_loss_t0: 1.4599868\n",
            "step: 1/100, G_loss_U: -4.3354583, G_loss_S: 0.015146872, E_loss_t0: 1.4564859\n",
            "step: 1/100, G_loss_U: -4.3598676, G_loss_S: 0.014856603, E_loss_t0: 1.4464749\n",
            "step: 1/100, G_loss_U: -4.3842463, G_loss_S: 0.014990384, E_loss_t0: 1.4843005\n",
            "step: 1/100, G_loss_U: -4.408591, G_loss_S: 0.015277538, E_loss_t0: 1.5068672\n",
            "step: 1/100, G_loss_U: -4.4329157, G_loss_S: 0.014981398, E_loss_t0: 1.5169535\n",
            "step: 1/100, G_loss_U: -4.457204, G_loss_S: 0.014971409, E_loss_t0: 1.5548073\n",
            "step: 1/100, G_loss_U: -4.481462, G_loss_S: 0.015435191, E_loss_t0: 1.5423543\n",
            "step: 1/100, G_loss_U: -4.5057006, G_loss_S: 0.015246908, E_loss_t0: 1.5518703\n",
            "step: 1/100, G_loss_U: -4.529902, G_loss_S: 0.016075429, E_loss_t0: 1.5797471\n",
            "step: 1/100, G_loss_U: -4.554093, G_loss_S: 0.015585085, E_loss_t0: 1.5997771\n",
            "step: 1/100, G_loss_U: -4.5782514, G_loss_S: 0.01590914, E_loss_t0: 1.5493008\n",
            "step: 1/100, G_loss_U: -4.602384, G_loss_S: 0.015837114, E_loss_t0: 1.5583091\n",
            "step: 1/100, G_loss_U: -4.626485, G_loss_S: 0.01450207, E_loss_t0: 1.5350056\n",
            "step: 1/100, G_loss_U: -4.65056, G_loss_S: 0.015663434, E_loss_t0: 1.557674\n",
            "step: 1/100, G_loss_U: -4.6746135, G_loss_S: 0.01590064, E_loss_t0: 1.5631185\n",
            "step: 1/100, G_loss_U: -4.6986413, G_loss_S: 0.015005541, E_loss_t0: 1.6112812\n",
            "step: 1/100, G_loss_U: -4.722647, G_loss_S: 0.014316915, E_loss_t0: 1.626663\n",
            "step: 1/100, G_loss_U: -4.746633, G_loss_S: 0.015897935, E_loss_t0: 1.6052839\n",
            "step: 1/100, G_loss_U: -4.7705874, G_loss_S: 0.014654031, E_loss_t0: 1.5351028\n",
            "step: 1/100, G_loss_U: -4.79452, G_loss_S: 0.014706159, E_loss_t0: 1.5287482\n",
            "step: 1/100, G_loss_U: -4.8184342, G_loss_S: 0.015213823, E_loss_t0: 1.555248\n",
            "step: 1/100, G_loss_U: -4.8423214, G_loss_S: 0.016169315, E_loss_t0: 1.5952641\n",
            "step: 1/100, G_loss_U: -4.8661933, G_loss_S: 0.014717087, E_loss_t0: 1.6185185\n",
            "step: 1/100, G_loss_U: -4.8900375, G_loss_S: 0.015117436, E_loss_t0: 1.5366372\n",
            "step: 1/100, G_loss_U: -4.91386, G_loss_S: 0.014450047, E_loss_t0: 1.4821466\n",
            "step: 1/100, G_loss_U: -4.9376607, G_loss_S: 0.01610751, E_loss_t0: 1.4941167\n",
            "step: 1/100, G_loss_U: -4.9614334, G_loss_S: 0.015378761, E_loss_t0: 1.5320386\n",
            "step: 1/100, G_loss_U: -4.9851923, G_loss_S: 0.015846228, E_loss_t0: 1.6643562\n",
            "step: 1/100, G_loss_U: -5.0089345, G_loss_S: 0.015533478, E_loss_t0: 1.6707573\n",
            "step: 1/100, G_loss_U: -5.0326552, G_loss_S: 0.01564884, E_loss_t0: 1.6387457\n",
            "step: 1/100, G_loss_U: -5.0563493, G_loss_S: 0.014939685, E_loss_t0: 1.6014718\n",
            "step: 1/100, G_loss_U: -5.0800285, G_loss_S: 0.01578836, E_loss_t0: 1.5387242\n",
            "step: 1/100, G_loss_U: -5.1036887, G_loss_S: 0.015294421, E_loss_t0: 1.55378\n",
            "step: 1/100, G_loss_U: -5.1273293, G_loss_S: 0.016320236, E_loss_t0: 1.5498847\n",
            "step: 1/100, G_loss_U: -5.150952, G_loss_S: 0.0154601, E_loss_t0: 1.5644461\n",
            "step: 1/100, G_loss_U: -5.1745534, G_loss_S: 0.014468361, E_loss_t0: 1.5260928\n",
            "step: 1/100, G_loss_U: -5.1981435, G_loss_S: 0.016553413, E_loss_t0: 1.5303936\n",
            "step: 1/100, G_loss_U: -5.221706, G_loss_S: 0.015131167, E_loss_t0: 1.5276555\n",
            "step: 1/100, G_loss_U: -5.245254, G_loss_S: 0.015317008, E_loss_t0: 1.4809679\n",
            "step: 1/100, G_loss_U: -5.268783, G_loss_S: 0.015145393, E_loss_t0: 1.5310304\n",
            "step: 1/100, G_loss_U: -5.292287, G_loss_S: 0.014573361, E_loss_t0: 1.5462587\n",
            "step: 1/100, G_loss_U: -5.315785, G_loss_S: 0.0148004675, E_loss_t0: 1.5699701\n",
            "step: 1/100, G_loss_U: -5.339257, G_loss_S: 0.015192864, E_loss_t0: 1.5692719\n",
            "step: 2/100, G_loss_U: -5.3627143, G_loss_S: 0.015183598, E_loss_t0: 1.5594822\n",
            "step: 2/100, G_loss_U: -5.3861575, G_loss_S: 0.01545751, E_loss_t0: 1.5619518\n",
            "step: 2/100, G_loss_U: -5.4095855, G_loss_S: 0.015021811, E_loss_t0: 1.5467962\n",
            "step: 2/100, G_loss_U: -5.4329944, G_loss_S: 0.015117497, E_loss_t0: 1.5604113\n",
            "step: 2/100, G_loss_U: -5.456391, G_loss_S: 0.015202888, E_loss_t0: 1.5989072\n",
            "step: 2/100, G_loss_U: -5.4797683, G_loss_S: 0.015987469, E_loss_t0: 1.5824015\n",
            "step: 2/100, G_loss_U: -5.5031323, G_loss_S: 0.015959075, E_loss_t0: 1.6188236\n",
            "step: 2/100, G_loss_U: -5.5264797, G_loss_S: 0.015409578, E_loss_t0: 1.633437\n",
            "step: 2/100, G_loss_U: -5.549818, G_loss_S: 0.016397564, E_loss_t0: 1.6168118\n",
            "step: 2/100, G_loss_U: -5.5731316, G_loss_S: 0.015018744, E_loss_t0: 1.5049639\n",
            "step: 2/100, G_loss_U: -5.596435, G_loss_S: 0.014944593, E_loss_t0: 1.4673432\n",
            "step: 2/100, G_loss_U: -5.619719, G_loss_S: 0.015873691, E_loss_t0: 1.5448732\n",
            "step: 2/100, G_loss_U: -5.64299, G_loss_S: 0.015265921, E_loss_t0: 1.5722214\n",
            "step: 2/100, G_loss_U: -5.6662498, G_loss_S: 0.014569689, E_loss_t0: 1.624332\n",
            "step: 2/100, G_loss_U: -5.6894937, G_loss_S: 0.015344746, E_loss_t0: 1.5915124\n",
            "step: 2/100, G_loss_U: -5.7127204, G_loss_S: 0.015731385, E_loss_t0: 1.5406238\n",
            "step: 2/100, G_loss_U: -5.735934, G_loss_S: 0.016270831, E_loss_t0: 1.529786\n",
            "step: 2/100, G_loss_U: -5.7591343, G_loss_S: 0.014874237, E_loss_t0: 1.5346003\n",
            "step: 2/100, G_loss_U: -5.782322, G_loss_S: 0.01598044, E_loss_t0: 1.5258753\n",
            "step: 2/100, G_loss_U: -5.8054986, G_loss_S: 0.015593394, E_loss_t0: 1.6391914\n",
            "step: 2/100, G_loss_U: -5.828657, G_loss_S: 0.015210528, E_loss_t0: 1.6668216\n",
            "step: 2/100, G_loss_U: -5.851807, G_loss_S: 0.01543076, E_loss_t0: 1.5824828\n",
            "step: 2/100, G_loss_U: -5.8749413, G_loss_S: 0.0145240845, E_loss_t0: 1.513682\n",
            "step: 2/100, G_loss_U: -5.898062, G_loss_S: 0.016367024, E_loss_t0: 1.5113301\n",
            "step: 2/100, G_loss_U: -5.9211707, G_loss_S: 0.014729272, E_loss_t0: 1.5192112\n",
            "step: 2/100, G_loss_U: -5.9442677, G_loss_S: 0.015944319, E_loss_t0: 1.5835664\n",
            "step: 2/100, G_loss_U: -5.9673557, G_loss_S: 0.015278739, E_loss_t0: 1.621751\n",
            "step: 2/100, G_loss_U: -5.990425, G_loss_S: 0.015339448, E_loss_t0: 1.5561106\n",
            "step: 2/100, G_loss_U: -6.0134864, G_loss_S: 0.014638116, E_loss_t0: 1.5757749\n",
            "step: 2/100, G_loss_U: -6.036532, G_loss_S: 0.0152948545, E_loss_t0: 1.55205\n",
            "step: 2/100, G_loss_U: -6.059565, G_loss_S: 0.014377168, E_loss_t0: 1.5612578\n",
            "step: 2/100, G_loss_U: -6.0825925, G_loss_S: 0.015618829, E_loss_t0: 1.5315608\n",
            "step: 2/100, G_loss_U: -6.105604, G_loss_S: 0.015621723, E_loss_t0: 1.5539194\n",
            "step: 2/100, G_loss_U: -6.128608, G_loss_S: 0.015969647, E_loss_t0: 1.5707226\n",
            "step: 2/100, G_loss_U: -6.1515975, G_loss_S: 0.014754947, E_loss_t0: 1.5223799\n",
            "step: 2/100, G_loss_U: -6.174576, G_loss_S: 0.015273749, E_loss_t0: 1.5537121\n",
            "step: 2/100, G_loss_U: -6.1975417, G_loss_S: 0.015280387, E_loss_t0: 1.5473148\n",
            "step: 2/100, G_loss_U: -6.2204967, G_loss_S: 0.015953755, E_loss_t0: 1.5590652\n",
            "step: 2/100, G_loss_U: -6.243442, G_loss_S: 0.015330025, E_loss_t0: 1.5631647\n",
            "step: 2/100, G_loss_U: -6.2663765, G_loss_S: 0.015724279, E_loss_t0: 1.6067274\n",
            "step: 2/100, G_loss_U: -6.2892995, G_loss_S: 0.01584961, E_loss_t0: 1.6133835\n",
            "step: 2/100, G_loss_U: -6.312216, G_loss_S: 0.015035562, E_loss_t0: 1.592664\n",
            "step: 2/100, G_loss_U: -6.335115, G_loss_S: 0.015136472, E_loss_t0: 1.56385\n",
            "step: 2/100, G_loss_U: -6.3580112, G_loss_S: 0.015154213, E_loss_t0: 1.5574304\n",
            "step: 2/100, G_loss_U: -6.3808923, G_loss_S: 0.014809653, E_loss_t0: 1.481474\n",
            "step: 2/100, G_loss_U: -6.403761, G_loss_S: 0.015285081, E_loss_t0: 1.5028669\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-dc5747c11203>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         random_data = random_generator(batch_size=batch_size, z_dim=dim, \n\u001b[0;32m----> 8\u001b[0;31m                                        T_mb=extract_time(data)[0], max_seq_len=extract_time(data)[1])\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-81307a2f1257>\u001b[0m in \u001b[0;36mextract_time\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     48\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mmax_seq_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_seq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_seq_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFKdBugWo9OM"
      },
      "source": [
        "def TimeGAN(data, parameters):\n",
        "  hidden_dim = parameters[\"hidden_dim\"]\n",
        "  num_layers = parameters[\"num_layers\"]\n",
        "  iterations = parameters[\"iterations\"]\n",
        "  batch_size = parameters[\"batch_size\"]\n",
        "  module = parameters[\"module\"]\n",
        "  epoch = parameters[\"epoch\"]\n",
        "  no, seq_len, dim = np.asarray(data).shape\n",
        "  z_dim = dim\n",
        "  gamma = 1\n",
        "\n",
        "  Embedder = Time_GAN_module(input_size=z_dim, output_size=hidden_dim, hidden_dim=hidden_dim, n_layers=num_layers)\n",
        "  Recovery = Time_GAN_module(input_size=hidden_dim, output_size=dim, hidden_dim=hidden_dim, n_layers=n_layers)\n",
        "  Generator = Time_GAN_module(input_size=dim, output_size=hidden_dim, hidden_dim=hidden_dim, n_layers=n_layers)\n",
        "  Supervisor = Time_GAN_module(input_size=hidden_dim, output_size=hidden_dim, hidden_dim=hidden_dim, n_layers=n_layers-1)\n",
        "  Discriminator = Time_GAN_module(input_size=hidden_dim, output_size=1, hidden_dim=hidden_dim, n_layers=n_layers, activation=nn.Identity)\n",
        "\n",
        "  embedder_optimizer = optim.Adam(Embedder.parameters(), lr=0.001)\n",
        "  recovery_optimizer = optim.Adam(Recovery.parameters(), lr=0.001)\n",
        "  supervisor_optimizer = optim.Adam(Recovery.parameters(), lr=0.001)\n",
        "  discriminator_optimizer = optim.Adam(Discriminator.parameters(), lr=0.001)\n",
        "  generator_optimizer = optim.Adam(Generator.parameters(), lr=0.001)\n",
        "\n",
        "  # Embedding Network Training\n",
        "  print('Start Embedding Network Training')\n",
        "  for e in range(epoch): \n",
        "    for batch_index, X in enumerate(loader):\n",
        "        \n",
        "        MSE_loss = nn.MSELoss()\n",
        "        \n",
        "        H, _ = Embedder(X.float())\n",
        "        H = torch.reshape(H, (batch_size, seq_len, hidden_dim))\n",
        "\n",
        "        X_tilde, _ = Recovery(H)\n",
        "        X_tilde = torch.reshape(X_tilde, (batch_size, seq_len, dim))\n",
        "\n",
        "        E_loss0 = 10 * torch.sqrt(MSE_loss(X, X_tilde))  \n",
        "\n",
        "        Embedder.zero_grad()\n",
        "        Recovery.zero_grad()\n",
        "\n",
        "        E_loss0.backward(retain_graph=True)\n",
        "\n",
        "        embedder_optimizer.step()\n",
        "        recovery_optimizer.step()\n",
        "\n",
        "        if e in range(1,epoch) and batch_index == 0:\n",
        "            print('step: '+ str(e) + '/' + str(epoch) + ', e_loss: ' + str(np.sqrt(E_loss0.detach().numpy())))\n",
        "\n",
        "  print('Finish Embedding Network Training')\n",
        "\n",
        "  # Training only with supervised loss\n",
        "  print('Start Training with Supervised Loss Only')\n",
        "  for e in range(epoch): \n",
        "    for batch_index, X in enumerate(loader):\n",
        "\n",
        "        H, _ = Embedder(X.float())\n",
        "        H = torch.reshape(H, (batch_size, seq_len, hidden_dim))\n",
        "\n",
        "        H_hat_supervise, _ = Supervisor(H)\n",
        "        H_hat_supervise = torch.reshape(H_hat_supervise, (batch_size, seq_len, hidden_dim))  \n",
        "\n",
        "        G_loss_S = MSE_loss(H[:,1:,:], H_hat_supervise[:,:-1,:])\n",
        "\n",
        "\n",
        "        Embedder.zero_grad()\n",
        "        Supervisor.zero_grad()\n",
        "\n",
        "        G_loss_S.backward(retain_graph=True)\n",
        "\n",
        "        embedder_optimizer.step()\n",
        "        supervisor_optimizer.step()\n",
        "\n",
        "        if e in range(1,epoch) and batch_index == 0:\n",
        "            print('step: '+ str(e) + '/' + str(epoch) + ', s_loss: ' + str(np.sqrt(G_loss_S.detach().numpy())))\n",
        "\n",
        "  print('Finish Training with Supervised Loss Only')\n",
        "  # Joint Training\n",
        "  print('Start Joint Training')\n",
        "  for itt in range(epoch):\n",
        "    for kk in range(2):\n",
        "      X = next(iter(loader))\n",
        "      random_data = random_generator(batch_size=batch_size, z_dim=dim, \n",
        "                                       T_mb=extract_time(data)[0], max_seq_len=extract_time(data)[1])\n",
        "        \n",
        "      # Generator Training \n",
        "      ## Train Generator\n",
        "      z = torch.tensor(random_data)\n",
        "      z = z.float()\n",
        "        \n",
        "      e_hat, _ = Generator(z)\n",
        "      e_hat = torch.reshape(e_hat, (batch_size, seq_len, hidden_dim))\n",
        "        \n",
        "      H_hat, _ = Supervisor(e_hat)\n",
        "      H_hat = torch.reshape(H_hat, (batch_size, seq_len, hidden_dim))\n",
        "        \n",
        "      Y_fake = Discriminator(H_hat)\n",
        "      Y_fake = torch.reshape(Y_fake, (batch_size, seq_len, 1))\n",
        "        \n",
        "      x_hat, _ = Recovery(H_hat)\n",
        "      x_hat = torch.reshape(x_hat, (batch_size, seq_len, dim))\n",
        "\n",
        "      Generator.zero_grad()\n",
        "      Supervisor.zero_grad()\n",
        "      Discriminator.zero_grad()\n",
        "      Recovery.zero_grad()\n",
        "        \n",
        "      G_loss_U = binary_cross_entropy_loss(torch.ones_like(Y_fake), Y_fake)\n",
        "        \n",
        "      G_loss_V1 = torch.mean(torch.abs((torch.std(x_hat, [0], unbiased = False)) + 1e-6 - (torch.std(X, [0]) + 1e-6)))\n",
        "      G_loss_V2 = torch.mean(torch.abs((torch.mean(x_hat, [0]) - (torch.mean(X, [0])))))\n",
        "      G_loss_V = G_loss_V1 + G_loss_V2\n",
        "        \n",
        " \n",
        "      G_loss_U.backward(retain_graph=True)\n",
        "      G_loss_V.backward()\n",
        "\n",
        "\n",
        "      generator_optimizer.step()\n",
        "      supervisor_optimizer.step()\n",
        "      discriminator_optimizer.step()\n",
        "      # Train Embedder \n",
        "      MSE_loss = nn.MSELoss()\n",
        "        \n",
        "      H, _ = Embedder(X.float())\n",
        "      H = torch.reshape(H, (batch_size, seq_len, hidden_dim))\n",
        "\n",
        "      X_tilde, _ = Recovery(H)\n",
        "      X_tilde = torch.reshape(X_tilde, (batch_size, seq_len, dim))\n",
        "\n",
        "      E_loss0 = 10 * torch.sqrt(MSE_loss(X, X_tilde))  \n",
        "        \n",
        "      H_hat_supervise, _ = Supervisor(H)\n",
        "      H_hat_supervise = torch.reshape(H_hat_supervise, (batch_size, seq_len, hidden_dim))  \n",
        "\n",
        "      G_loss_S = MSE_loss(H[:,1:,:], H_hat_supervise[:,:-1,:])\n",
        "      E_loss = E_loss0  + 0.1 * G_loss_S\n",
        "        \n",
        "      G_loss_S.backward(retain_graph=True)\n",
        "      E_loss.backward()\n",
        "        \n",
        "      Embedder.zero_grad()\n",
        "      Recovery.zero_grad()\n",
        "      Supervisor.zero_grad()\n",
        "        \n",
        "      embedder_optimizer.step()\n",
        "      recovery_optimizer.step()\n",
        "      supervisor_optimizer.step()\n",
        "    # train Discriminator\n",
        "    for batch_index, X in enumerate(loader):\n",
        "      random_data = random_generator(batch_size=batch_size, z_dim=dim, \n",
        "                                       T_mb=extract_time(data)[0], max_seq_len=extract_time(data)[1])\n",
        "      \n",
        "      z = torch.tensor(random_data)\n",
        "      z = z.float()\n",
        "\n",
        "      H, _ = Embedder(X)\n",
        "      H = torch.reshape(H, (batch_size, seq_len, hidden_dim))\n",
        "\n",
        "      Y_real = Discriminator(H)\n",
        "      Y_real = torch.reshape(Y_real, (batch_size, seq_len, 1))\n",
        "      \n",
        "      e_hat, _ = Generator(z)\n",
        "      e_hat = torch.reshape(e_hat, (batch_size, seq_len, hidden_dim))\n",
        "\n",
        "      Y_fake_e = Discriminator(e_hat)\n",
        "      Y_fake_e = torch.reshape(Y_fake_e, (batch_size, seq_len, 1))\n",
        "        \n",
        "      H_hat, _ = Supervisor(e_hat)\n",
        "      H_hat = torch.reshape(H_hat, (batch_size, seq_len, hidden_dim))\n",
        "        \n",
        "      Y_fake = Discriminator(H_hat)\n",
        "      Y_fake = torch.reshape(Y_fake, (batch_size, seq_len, 1))\n",
        "        \n",
        "      x_hat, _ = Recovery(H_hat)\n",
        "      x_hat = torch.reshape(x_hat, (batch_size, seq_len, dim))\n",
        "\n",
        "      Generator.zero_grad()\n",
        "      Supervisor.zero_grad()\n",
        "      Discriminator.zero_grad()\n",
        "      Recovery.zero_grad()\n",
        "      Embedder.zero_grad()\n",
        "\n",
        "      D_loss_real = nn.BCEWithLogitsLoss()\n",
        "      DLR = D_loss_real(torch.ones_like(Y_real), Y_real)\n",
        "      D_loss_fake = nn.BCEWithLogitsLoss()\n",
        "      DLF = D_loss_fake(torch.zeros_like(Y_fake), Y_fake)\n",
        "      D_loss_fake_e = nn.BCEWithLogitsLoss()\n",
        "      DLF_e = D_loss_fake_e(torch.zeros_like(Y_fake_e), Y_fake_e)\n",
        "      D_loss = DLR + DLF + gamma * DLF_e\n",
        "\n",
        "      # D_loss.backward(retain_graph=True)\n",
        "\n",
        "      # check discriminator loss before updating\n",
        "      check_d_loss = D_loss\n",
        "      if (check_d_loss > 0.15):\n",
        "        D_loss.backward(retain_graph=True)\n",
        "        discriminator_optimizer.step()\n",
        "      \n",
        "      print('step: '+ str(e) + '/' + str(epoch) + ', G_loss_U: ' + str(G_loss_U.detach().numpy()) + ', G_loss_S: ' + \n",
        "             str(G_loss_S.detach().numpy()) + ', E_loss_t0: ' + str(np.sqrt(E_loss0.detach().numpy()))\n",
        "             )\n",
        "  print('Finish Joint Training')"
      ],
      "id": "GFKdBugWo9OM",
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPbbUH0dJqjt",
        "outputId": "7dd6d6eb-cf1c-41b7-b646-5f67ec09de64"
      },
      "source": [
        ""
      ],
      "id": "YPbbUH0dJqjt",
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([128, 24, 1])\n",
            "tensor(-6.4264, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rnug7qqmddM"
      },
      "source": [
        "parameters = dict()\n",
        "parameters['module'] = 'gru' \n",
        "parameters['hidden_dim'] = 24\n",
        "parameters['num_layers'] = 3\n",
        "parameters['iterations'] = 10000\n",
        "parameters['batch_size'] = 128\n",
        "parameters['epoch'] = 100"
      ],
      "id": "9rnug7qqmddM",
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uP_YyhAZpKXl"
      },
      "source": [
        "TimeGAN(data, parameters)"
      ],
      "id": "uP_YyhAZpKXl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3PHABnV9mBa",
        "outputId": "2bd0fc61-aaab-4fc9-d424-228cbd7b970f"
      },
      "source": [
        "test = next(iter(loader))\n",
        "test.shape"
      ],
      "id": "T3PHABnV9mBa",
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 24, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiPaUpnzsUnj"
      },
      "source": [
        ""
      ],
      "id": "PiPaUpnzsUnj",
      "execution_count": null,
      "outputs": []
    }
  ]
}