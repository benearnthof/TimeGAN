{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TimeGAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NakQP80GeSS"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrfyA_LUtlKW"
      },
      "source": [
        "# data loading and generation\n",
        "def Normalize(data):\n",
        "  numerator = data - np.min(data, 0)\n",
        "  denominator = np.max(data, 0) - np.min(data, 0)\n",
        "  norm_data = numerator / (denominator + 1e-7)\n",
        "  return norm_data"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ug0xl4eue2W",
        "outputId": "deea40be-36db-4f59-a89e-5a8010b9c4bd"
      },
      "source": [
        "dta = np.arange(10)\n",
        "dta = np.concatenate((dta, dta))\n",
        "# dta = np.stack((dta, dta))\n",
        "# dta\n",
        "Normalize(dta)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n",
              "       0.55555555, 0.66666666, 0.77777777, 0.88888888, 0.99999999,\n",
              "       0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n",
              "       0.55555555, 0.66666666, 0.77777777, 0.88888888, 0.99999999])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZUEjCwCumYt"
      },
      "source": [
        "def Normalize2(dta):\n",
        "  return (dta - np.min(dta, 0)) /  (np.max(dta, 0) - np.min(dta, 0) + 1e-7)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqzp-Y5UDLFz"
      },
      "source": [
        "def Normalize3(dta):\n",
        "  min = np.min(np.min(data, axis = 0), axis = 0)\n",
        "  dta = dta - min\n",
        "\n",
        "  max = np.max(np.max(dta, axis = 0), axis = 0)\n",
        "  norm_dta = dta / (max + 1e-7)\n",
        "  return norm_dta, min, max"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXLrOZfNvXk8",
        "outputId": "24007987-5285-43ac-98b3-502394b303bb"
      },
      "source": [
        "Normalize2(dta)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n",
              "       0.55555555, 0.66666666, 0.77777777, 0.88888888, 0.99999999,\n",
              "       0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n",
              "       0.55555555, 0.66666666, 0.77777777, 0.88888888, 0.99999999])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rlXKNFTwNg2"
      },
      "source": [
        "def sine_data_generation(no, seq_len, dim):\n",
        "  # number of samples, length of time series, feature dims\n",
        "  data = list()\n",
        "\n",
        "  for i in range(no):\n",
        "    temp = list()\n",
        "    for k in range(dim):\n",
        "      freq = np.random.uniform(0, 0.1)\n",
        "      phase = np.random.uniform(0, 0.1)\n",
        "      # gen sine signal based on freq and phase\n",
        "      temp_data = [np.sin(freq * j + phase) for j in range(seq_len)]\n",
        "      temp.append(temp_data)\n",
        "    # transpose\n",
        "    temp = np.transpose(np.asarray(temp))\n",
        "    # normalize data\n",
        "    temp = (temp + 1) * 0.5   \n",
        "    data.append(temp)\n",
        "  return data"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3UfK1CHxceQ"
      },
      "source": [
        "dta = sine_data_generation(1, 100, 1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paixiBPvz8kM"
      },
      "source": [
        "def sine_data_generation_orig (no, seq_len, dim):\n",
        "  \"\"\"Sine data generation.\n",
        "  \n",
        "  Args:\n",
        "    - no: the number of samples\n",
        "    - seq_len: sequence length of the time-series\n",
        "    - dim: feature dimensions\n",
        "    \n",
        "  Returns:\n",
        "    - data: generated data\n",
        "  \"\"\"  \n",
        "  # Initialize the output\n",
        "  data = list()\n",
        "\n",
        "  # Generate sine data\n",
        "  for i in range(no):      \n",
        "    # Initialize each time-series\n",
        "    temp = list()\n",
        "    # For each feature\n",
        "    for k in range(dim):\n",
        "      # Randomly drawn frequency and phase\n",
        "      freq = np.random.uniform(0, 0.1)            \n",
        "      phase = np.random.uniform(0, 0.1)\n",
        "          \n",
        "      # Generate sine signal based on the drawn frequency and phase\n",
        "      temp_data = [np.sin(freq * j + phase) for j in range(seq_len)] \n",
        "      temp.append(temp_data)\n",
        "        \n",
        "    # Align row/column\n",
        "    temp = np.transpose(np.asarray(temp))        \n",
        "    # Normalize to [0,1]\n",
        "    temp = (temp + 1)*0.5\n",
        "    # Stack the generated data\n",
        "    data.append(temp)\n",
        "                \n",
        "  return data"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2PUJMnzxkIz",
        "outputId": "9bb5ce4c-cb2f-4763-c2e6-46f46696c75b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "dta[0].shape[0]\n",
        "x = np.arange(dta[0].shape[0])\n",
        "y = dta[0] \n",
        "x = np.transpose(x)\n",
        "y = np.transpose(y)\n",
        "y = y[0]\n",
        "x.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "lTMxC4xGxkj-",
        "outputId": "fe981d1e-e75d-44a4-b3d1-b41651fcd574"
      },
      "source": [
        "plt.scatter(x,y)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f979d48da90>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "menPCTNXypDg"
      },
      "source": [
        "dta = sine_data_generation(2, 10, 3)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Db57CUJVzleT",
        "outputId": "40581edc-4af6-447b-86f9-4424c62375b0"
      },
      "source": [
        "dta"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[0.52195406, 0.5008712 , 0.51061288],\n",
              "        [0.56662478, 0.54505852, 0.51747489],\n",
              "        [0.6107595 , 0.58889318, 0.5243336 ],\n",
              "        [0.65400315, 0.63203211, 0.53118772],\n",
              "        [0.69600781, 0.67413767, 0.53803597],\n",
              "        [0.73643557, 0.71488032, 0.54487705],\n",
              "        [0.77496116, 0.75394119, 0.55170966],\n",
              "        [0.81127466, 0.79101456, 0.55853253],\n",
              "        [0.8450839 , 0.82581027, 0.56534437],\n",
              "        [0.87611689, 0.85805598, 0.57214389]]),\n",
              " array([[0.53990209, 0.51213489, 0.51679626],\n",
              "        [0.54004216, 0.52315171, 0.52856445],\n",
              "        [0.54018222, 0.53415728, 0.54031678],\n",
              "        [0.54032227, 0.54514625, 0.55204673],\n",
              "        [0.54046233, 0.55611327, 0.56374778],\n",
              "        [0.54060238, 0.56705302, 0.57541346],\n",
              "        [0.54074243, 0.57796017, 0.58703727],\n",
              "        [0.54088247, 0.58882943, 0.59861276],\n",
              "        [0.54102251, 0.59965551, 0.61013351],\n",
              "        [0.54116255, 0.61043314, 0.62159313]])]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yMiCu5Bzl3r",
        "outputId": "2c3ba8b1-096e-4a55-a5ff-9f59afd3f19a"
      },
      "source": [
        "np.random.seed(1)\n",
        "dta1 = sine_data_generation(1, 10, 1)\n",
        "np.random.seed(1)\n",
        "dta2 = sine_data_generation_orig(1, 10, 1)\n",
        "dta1, dta2"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([array([[0.53598509],\n",
              "         [0.5567448 ],\n",
              "         [0.57740585],\n",
              "         [0.5979323 ],\n",
              "         [0.61828847],\n",
              "         [0.63843895],\n",
              "         [0.65834871],\n",
              "         [0.67798313],\n",
              "         [0.69730807],\n",
              "         [0.71628993]])], [array([[0.53598509],\n",
              "         [0.5567448 ],\n",
              "         [0.57740585],\n",
              "         [0.5979323 ],\n",
              "         [0.61828847],\n",
              "         [0.63843895],\n",
              "         [0.65834871],\n",
              "         [0.67798313],\n",
              "         [0.69730807],\n",
              "         [0.71628993]])])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lu6OWqU30OhC",
        "outputId": "e3124190-6a82-486e-f0a4-405da71c52d9"
      },
      "source": [
        "sum(dta1[0] == dta2[0])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([10])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-loXeTXN0prj"
      },
      "source": [
        "def real_data_loading (data_name, seq_len):\n",
        "  \"\"\"Load and preprocess real-world datasets.\n",
        "  \n",
        "  Args:\n",
        "    - data_name: stock or energy\n",
        "    - seq_len: sequence length\n",
        "    \n",
        "  Returns:\n",
        "    - data: preprocessed data.\n",
        "  \"\"\"  \n",
        "  assert data_name in ['stock','energy']\n",
        "  \n",
        "  if data_name == 'stock':\n",
        "    ori_data = np.loadtxt('data/stock_data.csv', delimiter = \",\",skiprows = 1)\n",
        "  elif data_name == 'energy':\n",
        "    ori_data = np.loadtxt('data/energy_data.csv', delimiter = \",\",skiprows = 1)\n",
        "        \n",
        "  # Flip the data to make chronological data\n",
        "  ori_data = ori_data[::-1]\n",
        "  # Normalize the data\n",
        "  ori_data = MinMaxScaler(ori_data)\n",
        "    \n",
        "  # Preprocess the dataset\n",
        "  temp_data = []    \n",
        "  # Cut data by sequence length\n",
        "  for i in range(0, len(ori_data) - seq_len):\n",
        "    _x = ori_data[i:i + seq_len]\n",
        "    temp_data.append(_x)\n",
        "        \n",
        "  # Mix the datasets (to make it similar to i.i.d)\n",
        "  idx = np.random.permutation(len(temp_data))    \n",
        "  data = []\n",
        "  for i in range(len(temp_data)):\n",
        "    data.append(temp_data[idx[i]])\n",
        "    \n",
        "  return data"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wc93GGm2cDo"
      },
      "source": [
        "def train_test_divide (data_x, data_x_hat, data_t, data_t_hat, train_rate = 0.8):\n",
        "  \"\"\"Divide train and test data for both original and synthetic data.\n",
        "  \n",
        "  Args:\n",
        "    - data_x: original data\n",
        "    - data_x_hat: generated data\n",
        "    - data_t: original time\n",
        "    - data_t_hat: generated time\n",
        "    - train_rate: ratio of training data from the original data\n",
        "  \"\"\"\n",
        "  # Divide train/test index (original data)\n",
        "  no = len(data_x)\n",
        "  idx = np.random.permutation(no)\n",
        "  train_idx = idx[:int(no*train_rate)]\n",
        "  test_idx = idx[int(no*train_rate):]\n",
        "    \n",
        "  train_x = [data_x[i] for i in train_idx]\n",
        "  test_x = [data_x[i] for i in test_idx]\n",
        "  train_t = [data_t[i] for i in train_idx]\n",
        "  test_t = [data_t[i] for i in test_idx]      \n",
        "    \n",
        "  # Divide train/test index (synthetic data)\n",
        "  no = len(data_x_hat)\n",
        "  idx = np.random.permutation(no)\n",
        "  train_idx = idx[:int(no*train_rate)]\n",
        "  test_idx = idx[int(no*train_rate):]\n",
        "  \n",
        "  train_x_hat = [data_x_hat[i] for i in train_idx]\n",
        "  test_x_hat = [data_x_hat[i] for i in test_idx]\n",
        "  train_t_hat = [data_t_hat[i] for i in train_idx]\n",
        "  test_t_hat = [data_t_hat[i] for i in test_idx]\n",
        "  \n",
        "  return train_x, train_x_hat, test_x, test_x_hat, train_t, train_t_hat, test_t, test_t_hat\n",
        "\n",
        "\n",
        "def extract_time (data):\n",
        "  \"\"\"Returns Maximum sequence length and each sequence length.\n",
        "  \n",
        "  Args:\n",
        "    - data: original data\n",
        "    \n",
        "  Returns:\n",
        "    - time: extracted time information\n",
        "    - max_seq_len: maximum sequence length\n",
        "  \"\"\"\n",
        "  time = list()\n",
        "  max_seq_len = 0\n",
        "  for i in range(len(data)):\n",
        "    max_seq_len = max(max_seq_len, len(data[i][:,0]))\n",
        "    time.append(len(data[i][:,0]))\n",
        "    \n",
        "  return time, max_seq_len"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0urfopc3JyC"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# helper to decide which architecture to use\n",
        "def rnn_cell(module_name, hidden_dim, num_inputs):\n",
        "  assert module_name in [\"gru\", \"lstm\", \"lstmLN\", \"AdaFNN\"]\n",
        "  if (module_name == \"gru\"):\n",
        "    rnn_cell = nn.GRUCell(input_size = num_inputs, hidden_size=hidden_dim)\n",
        "    # no activation function probably need to reimplement these layers to match \n",
        "    # the tf implementation \n",
        "    # also not sure about bias default in tf\n",
        "  elif (module_name == \"lstm\"):\n",
        "    rnn_cell = nn.LSTMCell(input_size=num_inputs, hidden_size=hidden_dim)\n",
        "  elif (module_name == \"lstmLN\"): \n",
        "    pass\n",
        "    # need to implement\n",
        "  elif (module_name == \"AdaFNN\"):\n",
        "    pass\n",
        "    # need to implement\n",
        "  return rnn_cell\n",
        "\n",
        "# https://github.com/daehwannam/pytorch-rnn-util/blob/ba4d5ada3581fd6711f792d3fe79e58755613ba9/rnn_util/seq.py"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEQiaSd17ydb"
      },
      "source": [
        "def random_generator (batch_size, z_dim, T_mb, max_seq_len):\n",
        "  \"\"\"Random vector generation.\n",
        "  \n",
        "  Args:\n",
        "    - batch_size: size of the random vector\n",
        "    - z_dim: dimension of random vector\n",
        "    - T_mb: time information for the random vector\n",
        "    - max_seq_len: maximum sequence length\n",
        "    \n",
        "  Returns:\n",
        "    - Z_mb: generated random vector\n",
        "  \"\"\"\n",
        "  Z_mb = list()\n",
        "  for i in range(batch_size):\n",
        "    temp = np.zeros([max_seq_len, z_dim])\n",
        "    temp_Z = np.random.uniform(0., 1, [T_mb[i], z_dim])\n",
        "    temp[:T_mb[i],:] = temp_Z\n",
        "    Z_mb.append(temp_Z)\n",
        "  return Z_mb"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eCF1JuW6jsK",
        "outputId": "300fa6bb-e0ab-4995-e857-b5ed3c022889"
      },
      "source": [
        "torch.manual_seed(1)\n",
        "rnn = nn.GRUCell(5, 10)\n",
        "#rnn = nn.GRUCell(10, 20)\n",
        "input = torch.randn(1, 5)\n",
        "hx = torch.randn(1, 10)\n",
        "res1 = rnn(input, hx)\n",
        "res1"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.2808,  0.4106, -0.7252, -0.6151, -0.5328,  0.8263, -0.6560, -0.5309,\n",
              "          0.5347,  0.0276]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpqWkkXL6poB"
      },
      "source": [
        "def batch_generator(data, time, batch_size):\n",
        "  \"\"\"Mini-batch generator.\n",
        "  \n",
        "  Args:\n",
        "    - data: time-series data\n",
        "    - time: time information\n",
        "    - batch_size: the number of samples in each batch\n",
        "    \n",
        "  Returns:\n",
        "    - X_mb: time-series data in each batch\n",
        "    - T_mb: time information in each batch\n",
        "  \"\"\"\n",
        "  no = len(data)\n",
        "  idx = np.random.permutation(no)\n",
        "  train_idx = idx[:batch_size]     \n",
        "            \n",
        "  X_mb = list(data[i] for i in train_idx)\n",
        "  T_mb = list(time[i] for i in train_idx)\n",
        "  \n",
        "  return X_mb, T_mb"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0ayFYCaCY4D"
      },
      "source": [
        "def timegan(ori_data, parameters):\n",
        "  # Basic Parameters\n",
        "  no, seq_len, dim = np.asarray(ori_data).shape\n",
        "  # max seq length and each sequence length\n",
        "  ori_time, max_seq_len = extract_time(ori_data)\n",
        "  # Normalization\n",
        "  ori_data, min, max = Normalize3(ori_data)\n",
        "  # Network Params\n",
        "  hidden_dim   = parameters['hidden_dim'] \n",
        "  num_layers   = parameters['num_layer']\n",
        "  iterations   = parameters['iterations']\n",
        "  batch_size   = parameters['batch_size']\n",
        "  module_name  = parameters['module'] \n",
        "  z_dim        = dim\n",
        "  gamma        = 1\n",
        "  # need to implement cells from scratch and bundle them up into the multi rnn cell\n",
        "  # https://r2rt.com/recurrent-neural-networks-in-tensorflow-ii.html\n",
        "  # actually we only have to use torch.nn.RNN, has a num_layers argument, also has a tanh argument\n",
        "  # so we don't even need to do it with cells i think!\n",
        "  # dynamic versions \n",
        "  # https://github.com/songyouwei/ABSA-PyTorch/blob/master/layers/dynamic_rnn.py\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LhVapECF2V8"
      },
      "source": [
        "def timegan(ori_data, parameters):\n",
        "  no, seq_len, dim = np.asarray(ori_data).shape\n",
        "  ori_time, max_seq_len = extract_time(ori_data)\n",
        "  ori_data, min, max = Normalize3(ori_data)\n",
        "  # Network Params\n",
        "  hidden_dim   = parameters['hidden_dim'] \n",
        "  num_layers   = parameters['num_layer']\n",
        "  iterations   = parameters['iterations']\n",
        "  batch_size   = parameters['batch_size']\n",
        "  module_name  = parameters['module'] \n",
        "  z_dim        = dim\n",
        "  gamma        = 1\n",
        "  input_dim    = 10 # todo set input dim dependent on original data\n",
        "  # Inputs are X, Z and T\n",
        "  def embedder(X, T):\n",
        "    # X input time series features, T input time information \n",
        "    # bias is initialized to ones by default in tensorflow 1.x\n",
        "    # todo: wrap the if elif stuff in a function\n",
        "    if (module_name == \"rnn\"): # \"todo:dependent on ori_data\"\n",
        "      e_cell = torch.nn.RNN(input_size = input_dim, hidden_size = hidden_dim, \n",
        "                            num_layers = num_layers, nonlinearity=\"tanh\", bias = True, batch_first= True)\n",
        "    elif (module_name == \"lstm\"):\n",
        "      pass\n",
        "    elif (module_name == \"gru\"):\n",
        "      pass\n",
        "    elif (module_name == \"adafnn\"):\n",
        "      pass\n",
        "    # compute outputs\n",
        "    # dynamic rnn here https://github.com/songyouwei/ABSA-PyTorch/blob/master/layers/dynamic_rnn.py\n",
        "    # else we can just use the regular RNN function\n",
        "    # initialize h0 as learnable parameter? \n",
        "    h0 = torch.randn(num_layers, batch_size, hidden_size)\n",
        "    e_outputs, e_last_states = e_cell(X, h0)\n",
        "    # pass through fully connected layer \n",
        "    H = torch.sigmoid(nn.linear(e_outputs, hidden_dim))\n",
        "    return H\n",
        "    \n",
        "  def recovery (H, T):\n",
        "    if (module_name == \"rnn\"):\n",
        "      r_cell = torch.nn.RNN(input_size = input_dim, hidden_size = hidden_dim, \n",
        "                            num_layers = num_layers, nonlinearity=\"tanh\", bias = True, batch_first= True)\n",
        "    elif (module_name == \"lstm\"):\n",
        "      pass\n",
        "    elif (module_name == \"gru\"):\n",
        "      pass\n",
        "    elif (module_name == \"adafnn\"):\n",
        "      pass\n",
        "  \n",
        "    # get recovery\n",
        "    h0 = torch.randn(num_layers, batch_size, hidden_size)\n",
        "    r_outputs, r_last_states = r_cell(H, h0)\n",
        "    X_tilde = torch.sigmoid(nn.linear(r_outputs, dim)) # dimension of original data\n",
        "    return X_tilde\n",
        "  \n",
        "  def generator(Z, T):\n",
        "    # todo: define get_RNN function\n",
        "    e_cell = get_RNN(module_name, hidden_dim, input_dim, num_layers)\n",
        "    h0 = torch.randn(num_layers, batch_size, hidden_size)\n",
        "    e_outputs, e_last_states = e_cell(Z, h0)\n",
        "    E = torch.sigmoid(nn.linear(e_outputs, hidden_dim))\n",
        "    return E\n",
        "  \n",
        "  def supervisor(H, T):\n",
        "    # todo: Wrap all this in another function so we can dynamically adjust everything\n",
        "    # with a single function call\n",
        "    e_cell = get_RNN(module_name, hidden_dim, input_dim, num_layers)\n",
        "    h0 = torch.randn(num_layers, batch_size, hidden_size)\n",
        "    e_outputs, e_last_states = e_cell(H, h0)\n",
        "    S = torch.sigmoid(nn.linear(e_outputs, hidden_dim))\n",
        "    return S\n",
        "\n",
        "  def discriminator(H, T):\n",
        "    # todo: add dynamic sequence length \n",
        "    d_cell = getRNN(module_name, hidden_dim, input_dim, num_layers)\n",
        "    h0 = torch.randn(num_layers, batch_size, hidden_size)\n",
        "    d_outputs, d_last_states = d_cell(H, h0)\n",
        "    Y_hat = nn.linear(d_outputs, 1)\n",
        "    return Y_hat\n",
        "\n",
        "  # Embedder & Recovery\n",
        "  H = embedder(X, T)\n",
        "  X_tilde = recovery(H, T)\n",
        "    \n",
        "  # Generator\n",
        "  E_hat = generator(Z, T)\n",
        "  H_hat = supervisor(E_hat, T)\n",
        "  H_hat_supervised = supervisor(H, T)\n",
        "    \n",
        "  # Synthetic data\n",
        "  X_hat = recovery(H_hat, T)\n",
        "    \n",
        "  # Discriminator\n",
        "  Y_fake = discriminator(H_hat, T)\n",
        "  Y_real = discriminator(H, T)     \n",
        "  Y_fake_e = discriminator(E_hat, T)\n",
        "\n",
        "  # i think parameters are trainable by default in pytorch (?)\n",
        "  # if it doesn't work we need to add as torch parameter\n",
        "  # self.alpha = nn.Parameter(torch.tensor(0.5, requires_grad=True))\n",
        "  # https://discuss.pytorch.org/t/how-to-make-a-tensor-part-of-model-parameters/51037/6\n",
        "\n",
        "  # Discriminator loss \n",
        "  # i think we need to use logits, not 100% sure\n",
        "  # D_loss_real = nn.BCELoss(torch.ones_like(Y_real), Y_real)\n",
        "  D_loss_real = nn.BCEWithLogitsLoss(torch.ones_like(Y_real), Y_real)\n",
        "  D_loss_fake = nn.BCEWithLogitsLoss(torch.zeros_like(Y_fake), Y_fake)\n",
        "  D_loss_fake_e = nn.BCEWithLogitsLoss(torch.zeros_like(Y_fake_e), Y_fake_e)\n",
        "  D_loss = D_loss_real + D_loss_fake + gamma * D_loss_fake_e\n",
        "\n",
        "  # Generator loss\n",
        "  # Adversarial loss\n",
        "  G_loss_U = nn.BCEWithLogitsLoss(torch.ones_like(Y_fake), Y_fake)\n",
        "  G_loss_U_e = nn.BCEWithLogitsLoss(torch_ones_like(Y_fake_e), Y_fake_e)\n",
        "\n",
        "  # Supervised loss\n",
        "  # h is the return value of the embedding network => need to pay attention to \n",
        "  # shapes of returned tensors\n",
        "  G_loss_S = nn.MSELoss(H[:,1,:], H_hat_supervised[:,:-1,:])\n",
        "\n",
        "  # two moments\n",
        "  \n",
        "  "
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zLiLMmB7Vh_",
        "outputId": "0370106b-4319-451b-a6b0-ca3c4e3f7a1b"
      },
      "source": [
        "nn.BCELoss(torch.ones(1), torch.zeros(1))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BCELoss()"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AA6a5nCwZE7H",
        "outputId": "2ebc83af-afe5-4d89-ee9e-dc45dbe62709"
      },
      "source": [
        "loss = nn.BCEWithLogitsLoss()\n",
        "input = torch.randn(3, requires_grad=True)\n",
        "target = torch.empty(3).random_(2)\n",
        "output = loss(input, target)\n",
        "output"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.3768, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGDue0fHAA9s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSwXivP9Zbam"
      },
      "source": [
        ""
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nz1H6QtyaEsa"
      },
      "source": [
        ""
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-cybIWZaSFy"
      },
      "source": [
        ""
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEHCN9nYaSio"
      },
      "source": [
        ""
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7r4TICfaisz"
      },
      "source": [
        ""
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDaUrz30ao6C"
      },
      "source": [
        "test = torch.nn.RNN(input_size = 5, hidden_size= 10, num_layers=2, nonlinearity=\"tanh\", bias = True, batch_first=True)\n",
        "input = torch.randn(1, 10, 5)\n",
        "h0 = torch.randn(2, 1, 10)\n",
        "output, hn = test(input, h0)\n",
        "output"
      ],
      "execution_count": 27,
      "outputs": []
    }
  ]
}